{
	"1": {
		"createDate": "20240101",
		"title": "웹 서비스 캐시 똑똑하게 다루기",
		"image": "https://wp.toss.tech/wp-content/uploads/2021/04/techblog-02-webcash.png",
		"content": "토스 프론트엔드 챕터에서는 웹 성능을 최대한으로 높이기 위해 HTTP 캐시를 적극적으로 사용하고 있습니다. 캐시를 잘못 관리했을 때, 원하는 시점에 캐시가 사라지지 않을 수 있습니다. 필요 이상으로 HTTP 요청이 발생하기도 합니다.HTTP 캐시를 효율적으로 관리하려면 Cache-Control 헤더를 섬세하게 조절해야 합니다. 토스 프론트엔드 챕터에서 다양한 생명 주기를 가지는 캐시를 다루면서 알게 된 노하우를 테크 블로그로 공유합니다.캐시의 생명 주기HTTP에서 리소스(Resource)란 웹 브라우저가 HTTP 요청으로 가져올 수 있는 모든 종류의 파일을 말합니다. 대표적으로 HTML, CSS, JS, 이미지, 비디오 파일 등이 리소스에 해당합니다.웹 브라우저가 서버에서 지금까지 요청한 적이 없는 리소스를 가져오려고 할 때, 서버와 브라우저는 완전한 HTTP 요청/응답을 주고받습니다. HTTP 요청도 완전하고, 응답도 완전합니다. 이후 HTTP 응답에 포함된 Cache-Control 헤더에 따라 받은 리소스의 생명 주기가 결정됩니다.캐시의 유효 기간: max-age서버의 Cache-Control 헤더의 값으로 max-age=<seconds> 값을 지정하면, 이 리소스의 캐시가 유효한 시간은 <seconds> 초가 됩니다.캐시의 유효 기간이 지나기 전한 번 받아온 리소스의 유효 기간이 지나기 전이라면, 브라우저는 서버에 요청을 보내지 않고 디스크 또는 메모리에서만 캐시를 읽어와 계속 사용합니다.메모리 캐시에서 불러온 HTTP 리소스예를 들어, 위 개발자 도구 캡처와 같이 어떤 JavaScript 파일을 요청하는 경우를 가정합시다. 이 리소스가 가지는 Cache-Control 헤더 값은 max-age=31536000 이기 때문에, 이 리소스는 1년(31,536,000초)동안 캐시할 수 있습니다.스크린샷에서는 유효한 캐시가 메모리에 남아 있기 때문에 (from memory cache) 라고 표기된 것을 확인할 수 있습니다.“서버에 요청을 보내지 않고” 라고 하는 말에 주의합시다. 한번 브라우저에 캐시가 저장되면 만료될 때까지 캐시는 계속 브라우저에 남아 있게 됩니다. 때문에 CDN Invalidation을 포함한 서버의 어떤 작업이 있어도 브라우저의 유효한 캐시를 지우기는 어렵습니다.Note: Cache-Control max-age 값 대신 Expires 헤더로 캐시 만료 시간을 정확히 지정할 수도 있습니다.캐시의 유효 기간이 지난 이후: 재검증그렇다면 캐시의 유효 기간이 지나면 캐시가 완전히 사라지게 될까요? 그렇지는 않습니다. 대신 브라우저는 서버에 조건부 요청(Conditional request)을 통해 캐시가 유효한지 재검증(Revalidation)을 수행합니다.재검증 결과 브라우저가 가지고 있는 캐시가 유효하다면, 서버는 [304 Not Modified] 요청을 내려줍니다. [304 Not Modified] 응답은 HTTP 본문을 포함하지 않기 때문에 매우 빠르게 내려받을 수 있습니다. 예를 들어, 위 스크린샷을 살펴보면 59.1KB 리소스의 캐시 검증을 위해 324바이트만의 네트워크 송수신만을 주고받았음을 볼 수 있습니다.If-None-Match와 If-Modified-Since가 포함된 요청대표적인 재검증 요청 헤더들로는 아래와 같은 헤더가 있습니다.If-None-Match: 캐시된 리소스의 ETag 값과 현재 서버 리소스의 ETag 값이 같은지 확인합니다.If-Modified-Since: 캐시된 리소스의 Last-Modified 값 이후에 서버 리소스가 수정되었는지 확인합니다.위의 ETag 와 Last-Modified 값은 기존에 받았던 리소스의 응답 헤더에 있는 값을 사용합니다.재검증 결과 캐시가 유효하지 않으면, 서버는 [200 OK] 또는 적합한 상태 코드를 본문과 함께 내려줍니다. 추가로 HTTP 요청을 보낼 필요 없이 바로 최신 값을 내려받을 수 있기 때문에 매우 효율적이죠. 😉max-age=0 주의보 정의대로라면 max-age=0 값이 Cache-Control 헤더로 설정되었을 때, 매번 리소스를 요청할 때마다 서버에 재검증 요청을 보내야 할 것입니다. 그렇지만 일부 모바일 브라우저의 경우 웹 브라우저를 껐다 켜기 전까지 리소스가 만료되지 않도록 하는 경우가 있습니다. 네트워크 요청을 아끼고 사용자에게 빠른 웹 경험을 제공하기 위해서라고 합니다.이 경우에는 웹 브라우저를 껐다 켜거나, 아래에서 소개할 no-store 값을 사용해주세요.no-cache와 no-storeCache-Control에서 가장 헷갈리는 두 가지 값이 있다면 바로 no-cache 와 no-store 입니다. 이름은 비슷하지만 두 값의 동작은 매우 다릅니다.no-cache 값은 대부분의 브라우저에서 max-age=0 과 동일한 뜻을 가집니다. 즉, 캐시는 저장하지만 사용하려고 할 때마다 서버에 재검증 요청을 보내야 합니다.no-store 값은 캐시를 절대로 해서는 안 되는 리소스일 때 사용합니다. 캐시를 만들어서 저장조차 하지 말라는 가장 강력한 Cache-Control 값입니다. no-store를 사용하면 브라우저는 어떤 경우에도 캐시 저장소에 해당 리소스를 저장하지 않습니다.캐시의 위치CDN과 같은 중간 서버를 사용할 때, 캐시는 여러 곳에 생길 수 있습니다. 서버가 가지고 있는 원래 응답을 CDN이 캐시합니다. CDN의 캐시된 응답은 사용자 브라우저가 다시 가져와서 캐시합니다. 이처럼 HTTP 캐시는 여러 레이어에 저장될 수 있기 때문에 세심히 다루어야 합니다.CDN Invalidation일반적으로 캐시를 없애기 위해서 “CDN Invalidation”을 수행한다고 이야기합니다. CDN Invalidation은 위 다이어그램에서 가운데에 위치하는 CDN에 저장되어 있는 캐시를 삭제한다는 뜻입니다. 브라우저의 캐시는 다른 곳에 위치하기 때문에 CDN 캐시를 삭제한다고 해서 브라우저 캐시가 삭제되지는 않습니다.경우에 따라 중간 서버나 CDN이 여러 개 있는 경우도 발생하는데, 이 경우 전체 캐시를 날리려면 중간 서버 각각에 대해서 캐시를 삭제해야 합니다.이렇게 한번 저장된 캐시는 지우기 어렵기 때문에 Cache-Control의 max-age 값은 신중히 설정하여야 합니다.Cache-Control: public과 privateCDN과 같은 중간 서버가 특정 리소스를 캐시할 수 있는지 여부를 지정하기 위해 Cache-Control 헤더 값으로 public 또는 private을 추가할 수 있습니다.public은 모든 사람과 중간 서버가 캐시를 저장할 수 있음을 나타내고, private은 가장 끝의 사용자 브라우저만 캐시를 저장할 수 있음을 나타냅니다.기존과 max-age 값과 조합하려면 Cache-Control: public, max-age=86400 과 같이 콤마로 연결할 수 있습니다.s-maxage중간 서버에서만 적용되는 max-age 값을 설정하기 위해 s-maxage 값을 사용할 수 있습니다.예를 들어, Cache-Control 값을 s-maxage=31536000, max-age=0 과 같이 설정하면 CDN에서는 1년동안 캐시되지만 브라우저에서는 매번 재검증 요청을 보내도록 설정할 수 있습니다.토스에서의 Cache-Control토스 프론트엔드 챕터는 리소스의 성격에 따라 세심히 Cache-Control 헤더 값을 조절하고 있습니다.HTML 파일일반적으로 https://service.toss.im/toss-card/introduction 과 같은 HTML 리소스는 새로 배포가 이루어질 때마다 값이 바뀔 수 있습니다. 때문에 브라우저는 항상 HTML 파일을 불러올 때 새로운 배포가 있는지 확인해야 합니다.이런 리소스에 대해 토스 프론트엔드 챕터는 Cache-Control 값으로 max-age=0, s-maxage=31536000 을 설정했습니다. 이로써 브라우저는 HTML 파일을 가져올 때마다 서버에 재검증 요청을 보내고, 그 사이에 배포가 있었다면 새로운 HTML 파일을 내려받습니다.CDN은 계속해서 HTML 파일에 대한 캐시를 가지고 있도록 했습니다. 대신 배포가 이루어질 때마다 CDN Invalidation을 발생시켜 CDN이 서버로부터 새로운 HTML 파일들을 받아오도록 설정했습니다.JS, CSS 파일JavaScript나 CSS 파일은 프론트엔드 웹 서비스를 빌드할 때마다 새로 생깁니다. 토스 프론트엔드 챕터는 임의의 버전 번호를 URL 앞부분에 붙여서 빌드 결과물마다 고유한 URL을 가지도록 설정하고 있습니다.고유 버전 번호가 붙어 있는 JavaScript 파일이렇게 JS, CSS 파일을 관리했을 때, 같은 URL에 대해 내용이 바뀔 수 있는 경우는 없습니다. 내용이 바뀔 여지가 없으므로 리소스의 캐시가 만료될 일도 없습니다.이런 리소스에 대해 토스 프론트엔드 챕터는 Cache-Control 값으로 max-age의 최대치인 max-age=31536000 을 설정하고 있습니다. 이로써 새로 배포가 일어나지 않는 한, 브라우저는 캐시에 저장된 JavaScript 파일을 계속 사용합니다.캐시 설정을 섬세히 제어함으로써 사용자는 더 빠르게 HTTP 리소스를 로드할 수 있고, 개발자는 트래픽 비용을 절감할 수 있습니다. 위에서 Cache-Control와 ETag 헤더를 리소스의 성격에 따라 잘 설정하는 것만으로 캐시를 정확하게 설정할 수 있다는 것을 살펴보았습니다. HTTP 캐시로 고민하고 있는 분들께 도움이 되었기를 기대합니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"2": {
		"createDate": "20231223",
		"title": "JSCodeShift로 기술 부채 청산하기",
		"image": "https://wp.toss.tech/wp-content/uploads/2021/05/techblog-03-jscodeshift.png",
		"content": "토스 프론트엔드 챕터에서는 100개 이상의 서비스들이 작은 패키지 단위로 쪼개져 활발하게 개발되고 있는데요. 공통으로 사용하는 라이브러리에서 인터페이스가 변경되는 Breaking Change가 발생하면, 의존하고 있는 모든 서비스의 코드를 수정해야 했습니다. 관리하는 코드베이스가 점점 커지면서 해야 하는 작업의 양도 계속 늘어나고는 했습니다.이에 프론트엔드 챕터는 JSCodeShift를 도입하여 대부분의 코드 수정 작업을 자동화할 수 있었습니다. 토스팀이 JSCodeShift를 도입하면서 알게 된 점과 노하우를 테크 블로그로 공유합니다.JSCodeShift란?JSCodeShift는 Facebook이 만든 JavaScript/TypeScript 코드 수정 도구입니다. JSCodeShift를 통해 코드를 수정하는 코드를 작성할 수 있습니다.찾아 바꾸기와의 비교JSCodeShift를 도입하기 전, 토스에서는 대량의 코드 수정이 필요할 때면 IDE의 찾아 바꾸기(Find & Replace)를 사용했습니다. 그러나 찾아 바꾸기로는 안전하게 코드를 수정하는 데에 한계가 많았습니다.예시 1: console.log() 모두 삭제하기프로젝트 전체에 있는 console.log() 호출을 모두 제거하고 싶은 상황을 생각해봅시다. 간단한 예제임에도 쉽게 고칠 수 없는 엣지 케이스들이 발생합니다. 우선 console.log 안에 들어가는 인자의 내용이 달라질 수 있습니다. console.log에 여러 인자를 넘겨서 함수 호출이 여러 줄에 걸칠 수도 있습니다.이것을 정규식을 이용하여 어느 정도 해결할 수도 있습니다. 그러나 다양한 엣지케이스에 대응하기 위해서 정규식이 점점 복잡해지는 경우가 발생했습니다. 또 정규식은 정규 언어이기 때문에 기술적으로 대응할 수 없는 경우도 존재했습니다.예시 2: default import된 객체의 프로퍼티 수정하기아래와 같은 코드가 있었다고 생각해봅시다.import A from '@tossteam/a';\n\nA.foo();어느 순간 A.foo() 함수가 A.bar() 함수로 이름이 변경되었다고 가정해봅시다.Default import의 변수 이름은 사용하는 사람마다 임의로 정할 수 있기 때문에, 어떤 사람은 이 라이브러리를 B 라고 하는 이름으로 사용하고 있을 수도 있습니다. 때문에 이 라이브러리를 B.foo() 처럼 사용하고 있던 코드가 있었다면, B.bar() 로 수정해주어야 합니다.이런 경우는 찾아 바꾸기로 쉽게 대응하기 어렵습니다.JSCodeShift 기초JSCodeShift는 추상 구문 트리(AST, Abstract Syntax Tree)를 이용하여 코드를 수정하는 방법을 제공함으로써 코드 수정 작업을 정확하고 편리하게 할 수 있도록 도와줍니다.추상 구문 트리 (AST)추상 구문 트리는 프로그램의 소스 코드를 쉽게 다룰 수 있도록 도와주는 자료구조입니다.예를 들어서, 다음 import 문을 추상 구문 트리로 옮기면 이런 모습이 됩니다.import React, { useMemo } from 'react';ImportDeclaration {\n  specifiers: [\n    ImportDefaultSpecifier {\n      local: Identifier {\n        name: \"React\"\n      }\n    },\n    ImportSpecifier {\n      local: Identifier {\n        name: \"useMemo\"\n      }\n    }\n  ],\n  source: Literal {\n    value: \"react\"\n  }\n}살펴보면 import 문이 ImportDeclaration 객체로 바뀌었습니다. 또 내부에서 사용되는 Default Import와 Named Import, 라이브러리 이름이 알맞은 객체로 옮겨진 것을 확인할 수 있습니다.ASTExplorer작성한 코드의 추상 구문 트리를 ASTExplorer로 쉽게 확인할 수 있습니다. 코드만 붙여넣으면 해당하는 구문 트리를 바로 확인할 수 있어 편리합니다. 소스 코드의 특정 부분에 커서를 옮기면 그 부분이 트리의 어떤 부분에 해당하는지 바로 볼 수 있기도 합니다. 😉 추상 구문 트리에 익숙하지 않다면, 사용해보시는 것을 권장합니다.라이브러리별 추상 구문 트리라이브러리마다 사용하는 추상 구문 트리의 모습은 다를 수 있습니다. 예를 들어서 같은 JavaScript를 다루더라도 ESLint가 사용하는 트리와 Babel이 사용하는 트리는 약간 다릅니다. JSCodeShift는 Babel이 사용하는 트리를 사용하고 있습니다.ASTExplorer 상단 메뉴에서 사용할 추상 구문 트리를 선택할 수 있습니다. JSCodeShift가 사용하는 트리는 @babel/parser 입니다.JSCodeShift 사용하기JSCodeShift로 코드를 수정하는 과정은 크게 4가지 작업으로 나눌 수 있습니다.AST로 파싱: 파일의 소스 코드를 AST로 파싱합니다.수정할 노드 선택: AST에서 수정할 노드를 선택합니다.수정하기: 검색한 노드를 JSCodeShift가 제공하는 유틸리티로 코드를 변경시킵니다.소스 코드로 내보내기: 수정된 AST를 JavaScript 소스 코드로 내보냅니다.예를 들어, 이런 형식으로 코드를 작성합니다./* transformSomeCode.js */\nfunction transformSomeCode(file, { jscodeshift }) {\n  // 1. AST로 파싱\n  const tree = jscodeshift(file.source);\n\n  // 2. 수정할 노드 선택\n  const nodes = tree.find(...);\n\n  // 3. 수정\n  jscodeshift(nodes)\n    .remove() | .replaceWith() | .insertBefore()\n\n  // 4. 소스 코드로 내보내기\n  return tree.toSource();\n}이후 JSCodeShift CLI를 이용하여 jscodeshift -t transformSomeCode.js <target> 와 같은 명령을 실행하면 <target> 에 있는 소스 코드들이 transformSomeCode.js 에 정의된 규칙에 맞게 수정됩니다.이제 본격적으로 JSCodeShift에서 자주 사용되는 메서드들을 살펴보겠습니다.수정할 노드 선택하기: find()기본적으로 수정할 노드를 선택하기 위해 find() 함수를 사용합니다.예를 들어, react 라이브러리의 useMemo 를 가져오는 import 구문들을 선택하기 위해서는 아래와 같이 코드를 작성할 수 있습니다.const nodes = tree.find(\n  /* 찾을 AST 노드 타입 */\n  jscodeshift.ImportDeclaration,\n  /* 필터링할 함수 */\n  node => {\n    return (\n      /* ImportDeclaration 중에서 */\n      node.type === 'ImportDeclaration' &&\n      /* react 라이브러리에서 */\n      node.source.value === 'react' &&\n      /* 가져오는 것 중에서 */\n      node.specifiers.some(specifier => {\n        /* useMemo를 포함하는 것을 */\n        return (\n          specifier.type === 'ImportSpecifier' &&\n          specifier.imported.name === 'useMemo'\n        );\n      })\n      /* 선택한다 */\n    )\n  }\n);노드 삭제하기: remove()선택한 노드를 삭제하기 위해 remove() 함수를 사용합니다.예를 들어서, 아래와 같이 코드를 작성함으로써 선택한 node 의 목록을 삭제할 수 있습니다.for (const node of nodes) {\n  jscodeshift(node).remove();\n}노드를 다른 노드로 치환하기: replaceWith()선택한 노드를 새로운 노드로 치환하려고 할 때 replaceWith() 함수를 사용할 수 있습니다.예를 들어서, 선택한 node 들을 다른 모습으로 치환하기 위해서는 아래와 같이 코드를 작성할 수 있습니다.for (const node of nodes) {\n  /* 노드를 만드는 방법에 대해서 아래에서 더 자세히 다룹니다. */\n  const newNode = createNode();\n\n  jscodeshift(node).replaceWith(newNode);\n}새로운 노드 만들기replaceWith() 와 같은 함수에서 사용하기 위해서 새로운 노드를 만들 때는 JSCodeShift에서 제공하는 도우미 함수들을 사용할 수 있습니다.각 노드를 만드는 방법을 모두 알 필요는 없습니다. TypeScript를 사용하는 경우, 각 함수가 어떤 인자를 받는지 바로 확인할 수 있습니다. JavaScript를 사용하는 경우, ast-types가 정의하는 타입 정보를 참고해주세요.변수 참조: foo와 같은 변수에 참조하는 노드를 만들기 위해서 jscodeshift.identifier() 를 사용할 수 있습니다.jscodeshift.identifier('foo');멤버 접근: 변수 foo의 멤버 bar 에 접근하는 노드를 만들기 위해서 jscodeshift.memberExpression() 을 사용할 수 있습니다.jscodeshift.memberExpression(\n  jscodeshift.identifier('foo'),\n  jscodeshift.identifier('bar')\n);import 문: import { useMemo } from 'react'; 와 같은 import 문을 만들기 위해서 jscodeshift.importDeclaration() 을 사용할 수 있습니다.jscodeShift.importDeclaration(\n  [\n    jscodeShift.importSpecifier(\n      jscodeshift.identifier('useMemo')\n    )\n  ],\n  jscodeshift.literal('react')\n);JSCodeShift 사용 예시토스 프론트엔드 챕터에서는 2020년 import { Adaptive } from '@tossteam/web-development-kits' 와 같은 import 문을 모두 import { adaptive } from '@tossteam/colors' 으로 수정해야 하는 필요성이 있었습니다.이런 경우는 찾아 바꾸기로 해결하는 데에 어려움이 있었습니다. 코드를 수정하는 규칙이 복잡했기 때문입니다.@tossteam/web-development-kits 라이브러리로부터 Adaptive 뿐 아니라 다른 변수나 함수를 import 하는 경우가 있었습니다. 그런 경우에는 전체 import 문을 지우는 것이 아닌, Adaptive 를 가져오는 부분만 삭제해야 했습니다.Adaptive 를 import하는 부분이 삭제된 경우에만 import { adaptive } from '@tossteam/colors'; 와 같이 새로운 import 문을 파일의 가장 처음에 추가해주어야 했습니다. 아닌 경우, 사용하지 않은 변수로 인해 컴파일 시간에 오류가 발생했습니다.Adaptive 를 import하는 부분이 삭제된 경우에만 그 파일에서 사용되는 모든 Adaptive 변수를 adaptive 로 바꿔줘야 했습니다.다행히 토스팀에서는 간단히 이 문제를 JSCodeShift로 해결할 수 있었습니다. 저희가 설계한 JSCodeShift 변환 코드의 구조는 다음과 같습니다.function transformLegacyImportToNewImport(file, { jscodeshift }) {\n  const root = jscodeshift(file.source);\n\n  /* 오래된 import 문들을 찾음 */\n  const oldImports = findOldImports(root, { jscodeshift });\n\n  /* 오래된 import 문이 없는 파일인 경우, 아무 작업을 하지 않음 */\n  if (oldImports.length === 0) {\n    return;\n  }\n\n  for (const oldImport of oldImports) {\n    /* 오래된 import 문에서 Adaptive를 가져오는 부분을 삭제 */\n    /* (Adaptive만을 가져오는 import 문인 경우, import 문 전체를 삭제) */\n    removeImportMember(root, oldImport, 'Adaptive', { jscodeshift });\n  }\n\n  /* @tossteam/colors에서 adaptive를 import하는 부분을 추가 */\n  /* (@tossteam/colors를 import하고 있지 않은 경우, import 문을 추가) */\n  addImportMember(root, '@tossteam/colors', 'adaptive', { jscodeshift });\n\n  /* Adaptive 변수를 모두 adaptive로 치환 */\n  const oldAdaptives = findIdentifiers(root, 'Adaptive', { jscodeshift });\n\n  for (const oldAdaptive of oldAdaptives) {\n    jscodeshift(oldAdaptive).replaceWith(\n      jscodeshift.identifier('adaptive')\n    );\n  }\n\n  /* 수정된 소스코드를 반환 */\n  return root.toSource();\n}\n\n이 중에서 removeImportMember 함수와 같은 경우, 아래와 같이 간단히 구현할 수 있었습니다.function removeImportMember(root, importNode, name, { jscodeshift }) {\n  const oldSpecifiers = importNode.value.specifiers;\n\n  /* name을 import하는 부분을 삭제 */\n  const newSpecifiers = oldSpecifiers.filter(specifier => {\n    return (\n      specifier.type !== 'ImportSpecifier' ||\n      specifier.imported.name !== name\n    );\n  }\n\n  /* 더 이상 import할 것이 남지 않은 경우에는, import 문을 삭제 */\n  if (newSpecifiers.length === 0) {\n    jscodeshift(importNode).remove();\n    return;\n  }\n\n  /* 그렇지 않은 경우, import 문에서 name을 가져오는 부분만 삭제 */\n  jscodeshift(importNode).replaceWith(\n    jscodeshift.importDeclaration(\n      newSpecifiers,\n      importNode.value.source\n    )\n  );\n}다른 함수의 경우에도 유사하게 JSCodeShift API를 이용하여 구현할 수 있었습니다.JSCodeShift 테스트하기JSCodeShift는 작성한 변환 코드가 잘 작동하는지 테스트할 수 있도록 testUtils 라고 하는 이름의 테스트 도구를 제공합니다. 테스트 파일의 디렉토리 구조를 JSCodeShift가 요구하는 대로 맞춰야 하지만, 손쉽게 Jest에 테스트를 붙일 수 있어서 편리합니다.테스트가 잘 붙어 있으면, JSCodeShift 코드의 문제점을 바로바로 찾을 수 있게 됩니다. 개발 속도도 절약되는 만큼, JSCodeShift를 개발할 때는 꼭 테스트와 함께 하는 것을 추천합니다.JSCodeShift 테스트와 관련된 자세한 내용은 JSCodeShift README에서 확인할 수 있습니다.토스팀과 JSCodeShift토스 프론트엔드 개발팀은 짧은 시간동안 빠르게 개발환경을 개선해오면서 대량의 레거시 코드를 최신 라이브러리와 코드 컨벤션에 맞추도록 수정해주어야 했습니다. 경우에 따라서는 작성된지 2년이 지난 오래된 코드가 수만 줄 이상 존재하기도 했습니다.이때 JSCodeShift를 사용함으로써 그런 코드도 한번에 최신 코드와 같이 일관성을 맞출 수 있었습니다. 이번 JSCodeShift 가이드가 레거시 시스템을 다루는 다른 프론트엔드 개발자 분들께 도움이 되었으면 합니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"3": {
		"createDate": "20231215",
		"title": "node_modules로부터 우리를 구원해 줄 Yarn Berry",
		"image": "https://wp.toss.tech/wp-content/uploads/2021/05/techblog-04-yarn-berry.png",
		"content": "토스 프론트엔드 챕터에서는 100개 이상의 서비스들이 작은 패키지 단위로 쪼개져 활발하게 개발되고 있는데요. 공통으로 사용하는 라이브러리에서 인터페이스가 변경되는 Breaking Change가 발생하면, 의존하고 있는 모든 서비스의 코드를 수정해야 했습니다. 관리하는 코드베이스가 점점 커지면서 해야 하는 작업의 양도 계속 늘어나고는 했습니다.이에 프론트엔드 챕터는 JSCodeShift를 도입하여 대부분의 코드 수정 작업을 자동화할 수 있었습니다. 토스팀이 JSCodeShift를 도입하면서 알게 된 점과 노하우를 테크 블로그로 공유합니다.JSCodeShift란?JSCodeShift는 Facebook이 만든 JavaScript/TypeScript 코드 수정 도구입니다. JSCodeShift를 통해 코드를 수정하는 코드를 작성할 수 있습니다.찾아 바꾸기와의 비교JSCodeShift를 도입하기 전, 토스에서는 대량의 코드 수정이 필요할 때면 IDE의 찾아 바꾸기(Find & Replace)를 사용했습니다. 그러나 찾아 바꾸기로는 안전하게 코드를 수정하는 데에 한계가 많았습니다.예시 1: console.log() 모두 삭제하기프로젝트 전체에 있는 console.log() 호출을 모두 제거하고 싶은 상황을 생각해봅시다. 간단한 예제임에도 쉽게 고칠 수 없는 엣지 케이스들이 발생합니다. 우선 console.log 안에 들어가는 인자의 내용이 달라질 수 있습니다. console.log에 여러 인자를 넘겨서 함수 호출이 여러 줄에 걸칠 수도 있습니다.이것을 정규식을 이용하여 어느 정도 해결할 수도 있습니다. 그러나 다양한 엣지케이스에 대응하기 위해서 정규식이 점점 복잡해지는 경우가 발생했습니다. 또 정규식은 정규 언어이기 때문에 기술적으로 대응할 수 없는 경우도 존재했습니다.예시 2: default import된 객체의 프로퍼티 수정하기아래와 같은 코드가 있었다고 생각해봅시다.import A from '@tossteam/a';\n\nA.foo();어느 순간 A.foo() 함수가 A.bar() 함수로 이름이 변경되었다고 가정해봅시다.Default import의 변수 이름은 사용하는 사람마다 임의로 정할 수 있기 때문에, 어떤 사람은 이 라이브러리를 B 라고 하는 이름으로 사용하고 있을 수도 있습니다. 때문에 이 라이브러리를 B.foo() 처럼 사용하고 있던 코드가 있었다면, B.bar() 로 수정해주어야 합니다.이런 경우는 찾아 바꾸기로 쉽게 대응하기 어렵습니다.JSCodeShift 기초JSCodeShift는 추상 구문 트리(AST, Abstract Syntax Tree)를 이용하여 코드를 수정하는 방법을 제공함으로써 코드 수정 작업을 정확하고 편리하게 할 수 있도록 도와줍니다.추상 구문 트리 (AST)추상 구문 트리는 프로그램의 소스 코드를 쉽게 다룰 수 있도록 도와주는 자료구조입니다.예를 들어서, 다음 import 문을 추상 구문 트리로 옮기면 이런 모습이 됩니다.import React, { useMemo } from 'react';ImportDeclaration {\n  specifiers: [\n    ImportDefaultSpecifier {\n      local: Identifier {\n        name: \"React\"\n      }\n    },\n    ImportSpecifier {\n      local: Identifier {\n        name: \"useMemo\"\n      }\n    }\n  ],\n  source: Literal {\n    value: \"react\"\n  }\n}살펴보면 import 문이 ImportDeclaration 객체로 바뀌었습니다. 또 내부에서 사용되는 Default Import와 Named Import, 라이브러리 이름이 알맞은 객체로 옮겨진 것을 확인할 수 있습니다.ASTExplorer작성한 코드의 추상 구문 트리를 ASTExplorer로 쉽게 확인할 수 있습니다. 코드만 붙여넣으면 해당하는 구문 트리를 바로 확인할 수 있어 편리합니다. 소스 코드의 특정 부분에 커서를 옮기면 그 부분이 트리의 어떤 부분에 해당하는지 바로 볼 수 있기도 합니다. 😉 추상 구문 트리에 익숙하지 않다면, 사용해보시는 것을 권장합니다.라이브러리별 추상 구문 트리라이브러리마다 사용하는 추상 구문 트리의 모습은 다를 수 있습니다. 예를 들어서 같은 JavaScript를 다루더라도 ESLint가 사용하는 트리와 Babel이 사용하는 트리는 약간 다릅니다. JSCodeShift는 Babel이 사용하는 트리를 사용하고 있습니다.ASTExplorer 상단 메뉴에서 사용할 추상 구문 트리를 선택할 수 있습니다. JSCodeShift가 사용하는 트리는 @babel/parser 입니다.JSCodeShift 사용하기JSCodeShift로 코드를 수정하는 과정은 크게 4가지 작업으로 나눌 수 있습니다.AST로 파싱: 파일의 소스 코드를 AST로 파싱합니다.수정할 노드 선택: AST에서 수정할 노드를 선택합니다.수정하기: 검색한 노드를 JSCodeShift가 제공하는 유틸리티로 코드를 변경시킵니다.소스 코드로 내보내기: 수정된 AST를 JavaScript 소스 코드로 내보냅니다.예를 들어, 이런 형식으로 코드를 작성합니다./* transformSomeCode.js */\nfunction transformSomeCode(file, { jscodeshift }) {\n  // 1. AST로 파싱\n  const tree = jscodeshift(file.source);\n\n  // 2. 수정할 노드 선택\n  const nodes = tree.find(...);\n\n  // 3. 수정\n  jscodeshift(nodes)\n    .remove() | .replaceWith() | .insertBefore()\n\n  // 4. 소스 코드로 내보내기\n  return tree.toSource();\n}이후 JSCodeShift CLI를 이용하여 jscodeshift -t transformSomeCode.js <target> 와 같은 명령을 실행하면 <target> 에 있는 소스 코드들이 transformSomeCode.js 에 정의된 규칙에 맞게 수정됩니다.이제 본격적으로 JSCodeShift에서 자주 사용되는 메서드들을 살펴보겠습니다.수정할 노드 선택하기: find()기본적으로 수정할 노드를 선택하기 위해 find() 함수를 사용합니다.예를 들어, react 라이브러리의 useMemo 를 가져오는 import 구문들을 선택하기 위해서는 아래와 같이 코드를 작성할 수 있습니다.const nodes = tree.find(\n  /* 찾을 AST 노드 타입 */\n  jscodeshift.ImportDeclaration,\n  /* 필터링할 함수 */\n  node => {\n    return (\n      /* ImportDeclaration 중에서 */\n      node.type === 'ImportDeclaration' &&\n      /* react 라이브러리에서 */\n      node.source.value === 'react' &&\n      /* 가져오는 것 중에서 */\n      node.specifiers.some(specifier => {\n        /* useMemo를 포함하는 것을 */\n        return (\n          specifier.type === 'ImportSpecifier' &&\n          specifier.imported.name === 'useMemo'\n        );\n      })\n      /* 선택한다 */\n    )\n  }\n);노드 삭제하기: remove()선택한 노드를 삭제하기 위해 remove() 함수를 사용합니다.예를 들어서, 아래와 같이 코드를 작성함으로써 선택한 node 의 목록을 삭제할 수 있습니다.for (const node of nodes) {\n  jscodeshift(node).remove();\n}노드를 다른 노드로 치환하기: replaceWith()선택한 노드를 새로운 노드로 치환하려고 할 때 replaceWith() 함수를 사용할 수 있습니다.예를 들어서, 선택한 node 들을 다른 모습으로 치환하기 위해서는 아래와 같이 코드를 작성할 수 있습니다.for (const node of nodes) {\n  /* 노드를 만드는 방법에 대해서 아래에서 더 자세히 다룹니다. */\n  const newNode = createNode();\n\n  jscodeshift(node).replaceWith(newNode);\n}새로운 노드 만들기replaceWith() 와 같은 함수에서 사용하기 위해서 새로운 노드를 만들 때는 JSCodeShift에서 제공하는 도우미 함수들을 사용할 수 있습니다.각 노드를 만드는 방법을 모두 알 필요는 없습니다. TypeScript를 사용하는 경우, 각 함수가 어떤 인자를 받는지 바로 확인할 수 있습니다. JavaScript를 사용하는 경우, ast-types가 정의하는 타입 정보를 참고해주세요.변수 참조: foo와 같은 변수에 참조하는 노드를 만들기 위해서 jscodeshift.identifier() 를 사용할 수 있습니다.jscodeshift.identifier('foo');멤버 접근: 변수 foo의 멤버 bar 에 접근하는 노드를 만들기 위해서 jscodeshift.memberExpression() 을 사용할 수 있습니다.jscodeshift.memberExpression(\n  jscodeshift.identifier('foo'),\n  jscodeshift.identifier('bar')\n);import 문: import { useMemo } from 'react'; 와 같은 import 문을 만들기 위해서 jscodeshift.importDeclaration() 을 사용할 수 있습니다.jscodeShift.importDeclaration(\n  [\n    jscodeShift.importSpecifier(\n      jscodeshift.identifier('useMemo')\n    )\n  ],\n  jscodeshift.literal('react')\n);JSCodeShift 사용 예시토스 프론트엔드 챕터에서는 2020년 import { Adaptive } from '@tossteam/web-development-kits' 와 같은 import 문을 모두 import { adaptive } from '@tossteam/colors' 으로 수정해야 하는 필요성이 있었습니다.이런 경우는 찾아 바꾸기로 해결하는 데에 어려움이 있었습니다. 코드를 수정하는 규칙이 복잡했기 때문입니다.@tossteam/web-development-kits 라이브러리로부터 Adaptive 뿐 아니라 다른 변수나 함수를 import 하는 경우가 있었습니다. 그런 경우에는 전체 import 문을 지우는 것이 아닌, Adaptive 를 가져오는 부분만 삭제해야 했습니다.Adaptive 를 import하는 부분이 삭제된 경우에만 import { adaptive } from '@tossteam/colors'; 와 같이 새로운 import 문을 파일의 가장 처음에 추가해주어야 했습니다. 아닌 경우, 사용하지 않은 변수로 인해 컴파일 시간에 오류가 발생했습니다.Adaptive 를 import하는 부분이 삭제된 경우에만 그 파일에서 사용되는 모든 Adaptive 변수를 adaptive 로 바꿔줘야 했습니다.다행히 토스팀에서는 간단히 이 문제를 JSCodeShift로 해결할 수 있었습니다. 저희가 설계한 JSCodeShift 변환 코드의 구조는 다음과 같습니다.function transformLegacyImportToNewImport(file, { jscodeshift }) {\n  const root = jscodeshift(file.source);\n\n  /* 오래된 import 문들을 찾음 */\n  const oldImports = findOldImports(root, { jscodeshift });\n\n  /* 오래된 import 문이 없는 파일인 경우, 아무 작업을 하지 않음 */\n  if (oldImports.length === 0) {\n    return;\n  }\n\n  for (const oldImport of oldImports) {\n    /* 오래된 import 문에서 Adaptive를 가져오는 부분을 삭제 */\n    /* (Adaptive만을 가져오는 import 문인 경우, import 문 전체를 삭제) */\n    removeImportMember(root, oldImport, 'Adaptive', { jscodeshift });\n  }\n\n  /* @tossteam/colors에서 adaptive를 import하는 부분을 추가 */\n  /* (@tossteam/colors를 import하고 있지 않은 경우, import 문을 추가) */\n  addImportMember(root, '@tossteam/colors', 'adaptive', { jscodeshift });\n\n  /* Adaptive 변수를 모두 adaptive로 치환 */\n  const oldAdaptives = findIdentifiers(root, 'Adaptive', { jscodeshift });\n\n  for (const oldAdaptive of oldAdaptives) {\n    jscodeshift(oldAdaptive).replaceWith(\n      jscodeshift.identifier('adaptive')\n    );\n  }\n\n  /* 수정된 소스코드를 반환 */\n  return root.toSource();\n}\n\n이 중에서 removeImportMember 함수와 같은 경우, 아래와 같이 간단히 구현할 수 있었습니다.function removeImportMember(root, importNode, name, { jscodeshift }) {\n  const oldSpecifiers = importNode.value.specifiers;\n\n  /* name을 import하는 부분을 삭제 */\n  const newSpecifiers = oldSpecifiers.filter(specifier => {\n    return (\n      specifier.type !== 'ImportSpecifier' ||\n      specifier.imported.name !== name\n    );\n  }\n\n  /* 더 이상 import할 것이 남지 않은 경우에는, import 문을 삭제 */\n  if (newSpecifiers.length === 0) {\n    jscodeshift(importNode).remove();\n    return;\n  }\n\n  /* 그렇지 않은 경우, import 문에서 name을 가져오는 부분만 삭제 */\n  jscodeshift(importNode).replaceWith(\n    jscodeshift.importDeclaration(\n      newSpecifiers,\n      importNode.value.source\n    )\n  );\n}다른 함수의 경우에도 유사하게 JSCodeShift API를 이용하여 구현할 수 있었습니다.JSCodeShift 테스트하기JSCodeShift는 작성한 변환 코드가 잘 작동하는지 테스트할 수 있도록 testUtils 라고 하는 이름의 테스트 도구를 제공합니다. 테스트 파일의 디렉토리 구조를 JSCodeShift가 요구하는 대로 맞춰야 하지만, 손쉽게 Jest에 테스트를 붙일 수 있어서 편리합니다.테스트가 잘 붙어 있으면, JSCodeShift 코드의 문제점을 바로바로 찾을 수 있게 됩니다. 개발 속도도 절약되는 만큼, JSCodeShift를 개발할 때는 꼭 테스트와 함께 하는 것을 추천합니다.JSCodeShift 테스트와 관련된 자세한 내용은 JSCodeShift README에서 확인할 수 있습니다.토스팀과 JSCodeShift토스 프론트엔드 개발팀은 짧은 시간동안 빠르게 개발환경을 개선해오면서 대량의 레거시 코드를 최신 라이브러리와 코드 컨벤션에 맞추도록 수정해주어야 했습니다. 경우에 따라서는 작성된지 2년이 지난 오래된 코드가 수만 줄 이상 존재하기도 했습니다.이때 JSCodeShift를 사용함으로써 그런 코드도 한번에 최신 코드와 같이 일관성을 맞출 수 있었습니다. 이번 JSCodeShift 가이드가 레거시 시스템을 다루는 다른 프론트엔드 개발자 분들께 도움이 되었으면 합니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"4": {
		"createDate": "20231208",
		"title": "Template Literal Types로 타입 안전하게 코딩하기",
		"image": "https://wp.toss.tech/wp-content/uploads/2021/05/techblog-05-template-literal.png",
		"content": "2020년 11월 TypeScript 4.1이 출시되면서 \"Template Literal Type\"을 사용할 수 있게 되었습니다. TypeScript로 JSON Parser를 만들거나, document.querySelector 의 결과 타입을 추론할 수 있게 되어 화제가 되었는데요. 이번 아티클에서는 Template Literal Type이란 무엇인지, 이를 바탕으로 어떻게 그런 결과물을 만들 수 있었는지 간단히 예시로 소개드리고자 합니다.Template Literal Type이란?간단히 말해, Template Literal Type이란 기존 TypeScript의 String Literal Type을 기반으로 새로운 타입을 만드는 도구입니다. 구체적인 예시로 Template Literal Type에 대해 자세히 살펴보겠습니다.예시 1: 가장 간단한 형태type Toss = 'toss';\n\n// type TossPayments = 'toss payments';\ntype TossPayments = `${Toss} payments`;TypeScript Playground가장 간단한 형태로, 원래 있던 'toss' 라고 하는 타입을 바탕으로 'toss payments' 라고 하는 타입을 만드는 경우를 생각할 수 있습니다.TypeScript 4.1 이전에는 이런 문자열 작업이 불가능했지만, Template Literal Type을 이용함으로써 보다 넓은 타입 연산이 가능해졌습니다.예시 2: 하나의 Union Typetype Toss = 'toss';\ntype Companies = 'core' | 'bank' | 'securities' | 'payments' | 'insurance';\n\n// type TossCompanies = 'toss core' | 'toss bank' | 'toss securities' | ...;\ntype TossCompanies = `${Toss} ${Companies}`TypeScript PlaygroundTemplate Literal Type을 Union type(합 타입)과 함께하면, 결과물도 Union Type이 됩니다.예를 들어, 위 예시에서 'toss' 타입과 'core' | 'bank' | 'securities' | ... 타입을 Template Literal Type으로 연결하면 'toss core' | 'toss bank' | 'toss securities' | ... 와 같이 확장되는 것을 확인할 수 있습니다.예시 3: 여러 개의 Union Typetype VerticalAlignment = \"top\" | \"middle\" | \"bottom\";\ntype HorizontalAlignment = \"left\" | \"center\" | \"right\";\n\n// type Alignment =\n//   | \"top-left\"    | \"top-center\"    | \"top-right\"\n//   | \"middle-left\" | \"middle-center\" | \"middle-right\"\n//   | \"bottom-left\" | \"bottom-center\" | \"bottom-right\"\ntype Alignment = `${VerticalAlignment}-${HorizontalAlignment}`;TypeScript Playground여러 개의 Union Type을 연결할 수도 있습니다.예를 들어, 위에서는 VerticalAlignment 타입과 HorizontalAlignment 타입을 연결하여, ${VerticalAlignment}-${HorizontalAlignment} 타입을 만들었습니다.원래라면 중복해서 Alignment 타입을 다시 정의해야 했겠지만, Template Literal Type을 사용함으로써 중복 없이 더욱 간결히 타입을 표현할 수 있게 되었습니다.예시 4: 반복되는 타입 정의 없애기문제 상황// 이벤트 이름이 하나 추가될 때마다....\ntype EventNames = 'click' | 'doubleClick' | 'mouseDown' | 'mouseUp';\n\ntype MyElement = {\n    addEventListener(eventName: EventNames, handler: (e: Event) => void): void;\n\n    // onEvent() 도 하나씩 추가해줘야 한다\n    onClick(e: Event): void;\n    onDoubleClick(e: Event): void;\n    onMouseDown(e: Event): void;\n    onMouseUp(e: Event): void;\n};이벤트에 대한 핸들러를 등록할 때, addEventListener('event', handler) 와 onEvent = handler 의 두 가지 형식을 모두 사용할 수 있는 MyElement 타입을 생각해봅시다.// 두 가지 방법 모두 사용할 수 있는 경우\nelement.addEventListener('click', () => alert('I am clicked!'));\nelement.onClick = () => alert('I am clicked!');예를 들어, click 이벤트를 구독할 때, 위의 두 가지 방법을 모두 사용할 수 있는 것입니다.요소에 추가할 수 있는 이벤트의 종류는 자주 변경되고는 합니다. 예를 들어, 브라우저 API가 바뀌면서 'pointerDown' 과 같은 이벤트가 새로 추가될 수 있습니다.이런 경우, TypeScript 4.1 이전에는 매번 수동으로 여러 곳의 타입을 수정해야 했습니다. 우선 addEventListener의 인자로 사용되는 이벤트 이름 EventNames 타입에 'pointerDown' 을 넣어야 했습니다. 또 onPointerDown 메서드를 명시해야 했습니다. 잊지 않고 두 곳을 수정해야 했기 때문에, 실수하기 쉬웠습니다.하지만 Template Literal Type을 이용하면 한 곳만 수정해도 모두에 반영되도록 할 수 있습니다.type EventNames = 'click' | 'doubleClick' | 'mouseDown' | 'mouseUp';\n\n// CapitalizedEventNames = 'Click' | 'DoubleClick' | ...;\ntype CapitalizedEventNames = Capitalize<EventNames>;\n\n// type HandlerNames = 'onClick' | 'onDoubleClick' | 'onMouseDown' | 'onMouseUp';\ntype HandlerNames = `on${CapitalizedEventNames}`;\n\ntype Handlers = {\n  [H in HandlerNames]: (event: Event) => void;\n};\n\n// 원래 MyElement 그대로 작동!\ntype MyElement = Handlers & {\n  addEventListener: (eventName: EventNames, handler: (event: Event) => void) => void;\n};위 코드를 한번 자세히 살펴봅시다.CapitalizedEventNames 타입을 정의할 때, TypeScript 4.1에서 추가된 Capitalize<T> 타입을 이용하여 EventNames의 첫 글자를 대문자로 만들었습니다.HandlerNames 타입을 만들 때, Template Literal Type으로 onClick 과 같이 on 접두사를 붙였습니다.Handlers 타입에서는 기존의 onClick, onMouseDown 과 같은 이벤트 핸들러를 메서드로 가지도록 했고,마지막으로 MyElement 에서는 addEventListener 메서드를 가지는 객체와 연결하여 원래와 동일한 동작을 하는 타입을 만들 수 있었습니다.이제 EventNames 만 수정하면 MyElement 에서 이벤트를 구독하는 양쪽 모두 대응이 되므로, 코드가 깔끔해지고 실수의 여지가 적어졌습니다. ✨Conditional Type과 더 강력한 추론하기Template Literal Type은 Conditional Type과 함께 더욱 강력하게 사용할 수 있습니다.Conditional Type 되짚어보기Conditional Type은 JavaScript의 삼항 연산자와 비슷하게 분기를 수행하면서, 타입을 추론하는 방법인데요. 고급 TypeScript 사용에서 강력한 타입 연산을 하기 위해서 빠지지 않습니다.Template Literal Type을 더 잘 다루기 위해 반드시 필요한 개념이므로, 간단한 예시로 Conditional Type을 사용하는 방법에 대해 살펴보겠습니다.예시 1: 제네릭 타입 인자 꺼내오기Conditional Type을 가장 자주 사용하는 경우로,  Promise<number>와 같은 타입에서 number 를 꺼내오고 싶은 상황을 생각해봅시다.type PromiseType<T> = T extends Promise<infer U> ? U : never;\n\n// type A = number\ntype A = PromiseType<Promise<number>>;\n\n// type B = string | boolean\ntype B = PromiseType<Promise<string | boolean>>;\n\n// type C = never\ntype C = PromiseType<number>;TypeScript Playground위 코드를 살펴보면, PromiseType<T> 타입에 Promise<number> 타입을 인자로 넘기면 number 타입을 얻고 있습니다.Conditional Type이 동작하는 방식을 간단히 알아봅시다.삼항 연산자처럼 생긴 부분 가운데 X extends Y 와 같이 생긴 조건 부분은 X 타입의 변수가 Y 타입에 할당될 수 있는지에 따라 참값이 평가됩니다.예시:true extends boolean: true 는 boolean 에 할당될 수 있으므로 참으로 평가됩니다.'toss' extends string: 'toss' 는 string 에 할당될 수 있으므로 참으로 평가됩니다.Array<{ foo: string }> extends Array<unknown>: 마찬가지로 참으로 평가됩니다.string extends number: 문자열은 숫자 타입에 할당될 수 없으므로 거짓입니다.boolean extends true: boolean 타입 가운데 false 는 true 에 할당될 수 없으므로 거짓입니다.조건식이 참으로 평가될 때에는 infer 키워드를 사용할 수 있습니다. 예를 들어, Promise<number> extends Promise<infer U> 와 같은 타입을 작성하면, U 타입은 number 타입으로 추론됩니다. 이후 참인 경우에 대응되는 식에서 추론된 U 타입을 사용할 수 있습니다.예를 들어, Promise<number> extends Promise<infer U> ? U : never 에서는 조건식이 참이고 U 타입이 number로 추론되므로, 이를 평가한 타입의 결과는 number 가 됩니다.반대로 number extends Promise<infer U> ? U : never 에서는 조건식이 거짓이므로 이를 평가한 결과는 never가 됩니다.예시 2: Tuple 다루기[string, number, boolean] 과 같은 TypeScript의 Tuple Type에서 그 꼬리 부분인 [number, boolean] 과 같은 부분만 가져오고 싶은 상황을 생각해봅시다.Conditional Type과 Variadic Tuple Type을 활용함으로써 이를 간단히 구현할 수 있습니다.type TailOf<T> = T extends [unknown, ...infer U] ? U : [];\n\n// type A = [boolean, number];\ntype A = TailOf<[string, boolean, number]>;TypeScript Playground첫 요소를 제외하고 ...infer U 구문을 이용하여 뒤의 요소들을 모두 선택한 것을 확인할 수 있습니다.이 외에 간단한 형태로 특정한 튜플이 비어 있는지 검사하기 위해서, 아래와 같은 IsEmpty<T> 타입을 정의할 수도 있습니다.type IsEmpty<T extends any[]> = T extends [] ? true : false;\n\n// type B = true\ntype B = IsEmpty<[]>;\n\n// type C = false\ntype C = IsEmpty<[number, string]>;TypeScript PlaygroundConditional Type에 대해 더 궁금하신 분은 TypeScript 공식 문서를 참고하시기 바랍니다.이제 Conditional Type과 Template Literal Type을 함께 사용했을 때 어떤 결과를 얻을 수 있는지 살펴봅시다.초급 예시 1: 간단한 추론type InOrOut<T> = T extends `fade${infer R}` ? R : never;\n\n// type I = \"In\"\ntype I = InOrOut<\"fadeIn\">;\n// type O = \"Out\"\ntype O = InOrOut<\"fadeOut\">;가장 간단한 예시로, 'fadeIn' | 'fadeOut' 과 같은 타입에서 앞의 fade 접두사를 버리고 'In' | 'Out' 만 가져오고 싶은 상황을 생각해봅시다.Promise<number> 에서 number 를 가져오는 것과 유사하게, Conditional Type을 이용하여 접두사를 제외할 수 있습니다.중급 예시 1: 문자열에서 공백 없애기위의 예시를 응용하면 문자열의 공백을 없애는 타입을 정의할 수 있습니다. 예를 들어, 아래와 같이 오른쪽의 공백을 모두 제거한 타입을 만들 수 있습니다.// type T = \"Toss\"\ntype T = TrimRight<\"Toss      \">;TrimRight<T> 타입은 재귀적 타입 선언을 활용합니다.type TrimRight<T extends string> =\n  T extends `${infer R} `\n    ? TrimRight<R>\n    : T;TypeScript Playground위 코드를 살펴보시면, infer R 문 뒤에 하나의 공백이 있는 것을 확인하실 수 있습니다.즉, T 타입의 오른쪽에 공백이 하나 있다면, 공백을 하나 빠뜨린 것을 R 타입으로 추론하고, 다시 TrimRight<R> 을 호출합니다.만약 공백이 더 이상 존재하지 않는다면, 원래 주어진 타입 그대로를 반환합니다.TypeScript에는 if 문이 존재하지 않지만, 만약 존재한다고 가정했을 때 아래와 같이 작성해볼 수 있습니다.type TrimRight<T extends string> =\n  if (T extends `${infer R} `) {\n    return TrimRight<R>;\n  } else {\n    return T;\n  }보다 재귀적인 구조를 잘 확인할 수 있습니다.중급 예시 2: 점으로 연결된 문자열 Split하기재귀적 타입 정의를 활용하면 'foo.bar.baz' 와 같은 타입을 ['foo', 'bar', 'baz'] 로 나누는 타입을 정의할 수 있습니다.type Split<S extends string> =\n  S extends `${infer T}.${infer U}`\n    ? [T, ...Split<U>]\n    : [S];\n\n// type S = [\"foo\", \"bar\", \"baz\"];\ntype S = Split<\"foo.bar.baz\">;TypeScript Playground주어진 S 타입에서 첫번째 점(.) 을 찾고, 그 앞 부분을 T, 뒷 부분을 U 로 추론합니다. 이후 이를 [T, ...Split<U>]와 같이 재귀적으로 하나씩 값을 이어 나가면서 원하는 결과 타입을 만들어 나갑니다.이 경우에도 if 문이 있다는 가정 하에 pseudo-code로 정리해볼 수 있습니다.type Split<S extends string> =\n  if (S extends `${infer T}.${infer U}`) {\n    return [T, ...Split<infer U>];\n  } else {\n    return [S];\n  }고급 예시: lodash.set() 함수 타입 추론하기lodash.set()는 아래와 같이 문자열로 된 접근자를 이용하여 객체의 깊은 프로퍼티까지 수정할 수 있는 함수입니다.const someObject = {\n  toss: {\n    core: {\n      client: {\n        platform: \"foo\"\n      }\n    }\n  }\n};\n\n// OK!\nlodashSet(someObject, \"toss.core.client\", { platform: 'bar' });\n\n// Error: 'bar' is not assignable to type '{ platform: string }';\nlodashSet(someObject, 'toss.core.client', 'bar');Template Literal Type이 있기 전, 이런 함수는 타입 안전하게 사용할 수 없어 세 번째 인자를 any 로 규정해야 했습니다. 그러나 위에서 살펴본 타입 정의를 조합하면 lodash.set() 를 더욱 안전하게 타이핑할 수 있습니다. 💯lodash.set() 함수를 정확하게 타이핑하기 위해서는 아래의 ValueOf<T, P> 타입이 필요합니다. ValueOf<T, P> 타입은 객체 T 와 접근 경로 P가 주어졌을 때, T 를 P 경로로 순서대로 접근했을 때 결과로 나오는 타입을 나타냅니다.interface Foo {\n  foo: {\n    bar: {\n      baz: string;\n    }\n  }\n}\n\n// type A = { bar: { baz: string } };\ntype A = ValueOf<Foo, ['foo']>;\n\n// type B = { baz: string };\ntype B = ValueOf<Foo, ['foo', 'bar']>;\n\n// type C = string;\ntype C = ValueOf<Foo, ['foo', 'bar', 'baz']>;만약에 위와 같은 ValueOf<T, P> 이 있다면, 위에서 만들었던 Split<S> 과 조합하여 쉽게 lodash.set() 함수에 타입을 부여할 수 있을 것입니다.function lodashSet<Type, Path>(\n  obj: Type,\n  path: Path,\n  value: ValueOf<Type, Split<Path>>\n): void;이제 ValueOf<T, P> 타입을 만들어봅시다. if 문과 내부 타입 선언이 있는 pseudo-code로 나타낸다면, 아래와 같이 코드를 작성할 수 있습니다.type ValueOf<Type, Paths> =\n  type Head = Paths[0];\n  type Tail = TailOf<Paths>;\n\n  if (/* Tail의 길이가 0이다 */) {\n    return Type[Head];\n  } else {\n    return ValueOf<Type[Head], Tail>;\n  }ValueOf<T, P> 타입이 그렇게 동작한다면, 위의 Foo 예시에서는 아래와 같이 차례대로 값이 계산될 것입니다.ValueOf<Foo, ['foo', 'bar']>\n== ValueOf<Foo['foo'], ['bar']>\n== ValueOf<Foo['foo']['bar'], []>\n== Foo['foo']['bar']작성했던 의사 코드를 유효한 TypeScript 코드로 나타내면 다음과 같습니다.type ValueOf<Type, Paths extends any[]> =\n  /*\n   * IsEmpty<TailOf<Paths>>가 참이면\n   * == TailOf<Paths>가 빈 Tuple이면\n   */\n  IsEmpty<TailOf<Paths>> extends true\n    ? Type[HeadOf<Paths>]\n    : ValueOf<Type[HeadOf<Paths>], TailOf<Paths>>;위 내용을 모두 조합하면 lodash.set()을 안전하게 다룰 수 있는데요. 실제로 동작하는 방식을 TypeScript Playground에서 확인해보실 수 있습니다. 😉Template Literal Type의 응용위에서 살펴본 바와 같이, Template Literal Type을 Conditional Type과 사용하면 더욱 많은 코드를 안전하게 사용할 수 있습니다. awesome-template-literal-types 레포지토리에는 상상력을 자극하는 Template Literal Type의 사용 예시들이 모여 있습니다.대표적으로 화제가 되었던 예시들에 대한 링크를 남기고 글을 맺습니다.1. TypeScript로 JSON 파서 만들기// type Json = { key1: ['value1', null]; key2: 'value2' };\ntype Json = ParseJson<'{ \"key1\": [\"value1\", null], \"key2\": \"value2\" }'>;코드와 같이 JSON 문자열을 바로 TypeScript 타입으로 옮길 수 있다는 Proof-of-concept로 화제가 되었습니다.2. document.querySelector를 타입 안전하게 사용하기const a = querySelector('div.banner > a.call-to-action'); //-> HTMLAnchorElement\nconst b = querySelector('input, div'); //-> HTMLInputElement | HTMLDivElement\nconst c = querySelector('circle[cx=\"150\"]') //-> SVGCircleElement\nconst d = querySelector('button#buy-now'); //-> HTMLButtonElement\nconst e = querySelector('section p:first-of-type'); //-> HTMLParagraphElementa 태그를 선택했을 때 결괏값이 HTMLAnchorElement가 되는 것을 확인하실 수 있습니다.3. Express의 Route Parameter로부터 타입 추론하기Express에서 사용하는 경로 문자열에서 Route Parameter의 타입을 추론할 수 있습니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"5": {
		"createDate": "20231201",
		"title": "개발자의 애질리티",
		"image": "https://wp.toss.tech/wp-content/uploads/2021/10/techblog-06-agility.png",
		"content": "이 글은 토스페이먼츠에 입사하신, 혹은 입사를 고려 중인 개발자분들을 위해 작성된 글입니다.애자일하게 일하기애자일하게 일한다는 것은 어떠한 의미일까요? 한 시간을 일하면 한 시간 만큼의 가치를 만들어 내는 방식이 아닐까 합니다. 예를 들어, 동작하는 함수를 구현하거나 난해한 개념을 이해하는 식으로요. Big up-front 설계과거에는 프로젝트 진행 초기부터 분석과 설계에 많은 시간을 투자했습니다. 전체 프로젝트의 ⅓ 이상이 분석과 설계일 정도로요. 문제는 프로젝트 기간의 ½ 시점에 요구사항이 크게 변한다면 결과물 하나 없이 다시 새로 시작해야 한다는 점이었습니다. 세상의 변화속도가 엄청나게 빨라진 지금, 초기 설계 비용이 큰 big up-front 설계가 항상 잘 들어맞지 않는다는 사실을 이제는 대부분의 사람이 알게 되었습니다.애자일 개발 방법론애자일 개발 방법론에서는 애초에 크게 설계하지 않습니다. 간단한 사용 시나리오를 작성하고 그것의 구현을 목표로 하는 짧은 주기를 가집니다. 거대한 아키텍처를 설계하지 않고 이번 주기(이터레이션(Iteration) 혹은 스프린트(Sprint))에서 달성할 수 있는 만큼의 설계를 추구합니다. (앞으로는 주기가 아닌 스프린트라고 표현하겠습니다.)예를 들어 카드 승인이 100가지의 하위 기능으로 구분할 수 있다면, 이번 스프린트의 목표를 그중에 3가지로 결정할 수 있습니다. 나머지 기능을 함께 확인하고 싶으면 어떻게 하냐구요? 애초에 3가지 기능 외에는 개발하지 않는다는 목표로 일을 진행하기 때문에 스프린트 목표 달성 여부를 확인할 때에도 오직 이 3가지 기능만 확인합니다. 이번 스프린트를 성공적으로 달성했다면 팀은 최소한 3개의 작은 기능을 획득할 수 있게 됩니다. 개발자들은 요구사항 전체가 아닌 이번 스프린트에 필요한 요구사항에 더 집중할 수 있게 되고, 만약 스프린트가 성공적으로 진행되었다면 3개의 기능을 제공하는 소프트웨어를 가지게 됩니다. 팀은 점진적으로 비즈니스에 대한 학습을 진행하면서 작지만 동작하는 일부 기능을 확실히 정복해 갈 수 있게 되는 것이죠. 이런 방식으로 팀은 매 스프린트 목표에 맞추어 성장하고, 그에 맞추어 제품도 계속 성장해 나가게 됩니다. 나아가 다음 스프린트에 전혀 다른 기능을 개발하더라도 충분히 다시 쓸 수 있는 동작하는 코드를 확보하게 됩니다. 이러한 점에서 애자일 개발 방법론은 투자한 만큼의 가치를 만드는 방식이라고 볼 수 있습니다.그림: 애자일 프로젝트에서의 기능과 시간의 관계그림: big up-front 설계가 적용된 프로젝트에서의 기능과 시간의 관계애자일 프로젝트는 시간에 비례하여 기능의 수가 증가하고, 비-애자일 프로젝트에서는 상대적으로 후반부에 기능이 집중적으로 증가함을 표현해 봤습니다.품질과 생산성어떤 코드를 보고 최고의 품질인지 판단하는 것은 매우 어려운 일입니다. 피카소조차도 더 탁월한 화가를 만난다면 자신의 작품에 몇 점을 매겨야 할지 애매할 수 있습니다.평범한 화가가 심혈을 기울인다고 하여 피카소 만큼 훌륭한 그림을 그릴 확률 역시 극히 낮을 것입니다. 이러한 논리는 개발자에게도 그대로 적용 가능합니다. 개인의 품질 역량을 10이라고 가정했을 때 평균적으로 8정도의 품질을 보여줄 확률이 높으며, 상당한 노력을 투입해야 10의 품질을 만들어 낸다고 생각할 수 있습니다. 따라서 11의 품질을 추구하게 된다면 생산성이 극적으로 저하될 수 있습니다. 기존의 코드를 개선하여 품질을 높이고자 한다면 어느 정도의 품질 개선을 목표로 해야 할까요? 만약 전체 코드를 복제한다면 품질 개선율 0%, 공정률 100%를 즉시 달성할 수 있습니다. 만약 품질 개선율 1%, 생산 공정률 100%를 달성하고자 한다면 전체 코드의 1%를 개선하는 만큼의 시간을 더 사용해야 합니다.품질을 더 개선하고 싶은데 스스로 해내기가 쉽지 않다고 판단된다면 다양한 주변 환경(동료, 메이트, 멘토, 팀, 단위 테스트 등)을 활용하여 성장 환경을 만들어 가는 것이 중요한 것 같습니다. 특히 토스페이먼츠에는 기술 논의를 즐기는 기술 덕후들이 꽤 많습니다. 내 주변이 나 때문에 활기 넘치게 만들어 보세요.핵심은 코드 리딩의 생산성대부분의 회사에는 다른 개발자들이 생산한 코드가 항상 산적해 있습니다. 어떤 기능을 개선하고 싶다면 다른 사람이 작성한 코드를 읽어야 하죠. 그래서 보통은 코드를 읽는 시간이 작성하는 시간보다 훨씬 깁니다. 따라서 읽기 좋은 코드를 만드는 것은 개발자의 삶에 굉장히 중요합니다.기존 코드를 읽는 것에 과도한 시간을 써야 한다면 기능 개선을 위한 준비 작업에만 상당한 시간을 소비하게 되어 생산성이 떨어지게 됩니다.읽기 좋은 코드를 만들어서 코드 리딩의 생산성을 향상시키는 것이 중요한 이유입니다.가능하다면 코드를 읽을 때 리팩토링 기술(Rename Method, Extract Method 등)을 활용하는 것이 좋습니다. 이러한 리팩토링을 Michael Feathers는 ‘탐색적 리팩토링(Exploratory Refactoring)’ 이라고 부르며, 이 과정에서 수정된 코드가 최종적으로 코드 저장소에 반영되지 않는다고 하더라도 충분히 가치있는 일입니다. 제가 느끼기에 Exploratory Refactoring은 정말로 효과적인 학습 프로세스이기 때문입니다.Exploratory Refactoring을 수행하게 되면 코드를 읽은 즉시 나의 해설을 표시하기 때문에 굉장히 적극적으로 코드 리딩이 되며, 코드 리딩의 주도권을 자연스럽게 리더(reader)가 가져가게 됩니다. 책을 읽었는데도 이해가 안되서 다시 읽어야 하는 것과 같은 수동적인 상태에서 벗어날 수 있게 됩니다. 따라서 Exploratory Refactoring은 탁월한 개발자가 탁월해지게 만들어주는 진정한 OP 기술입니다.리팩토링의 가치개발자들이 리팩토링의 욕구를 강하게 느낄 때는 보통 유지보수 비용이 과도한 경우입니다. 유지보수 비용이 높은 이유는 기능을 수정해야 하는데 어느 코드를 수정해야 할지, 몇 줄의 코드를 바꿔야 할지, 변경을 했다면 올바르게 변경했는지 등을 파악하기 어렵기 때문입니다.따라서 요구사항에 대응하는 코드가 어디인지 명확하게 찾아낼 수 있고, 수정한 부분의 동작이 정확한지 파악하기 쉽다면 유지보수 비용을 낮출 수 있습니다. 리팩토링의 목적은 이러한 부분을 달성하는 데 있습니다.따라서 리팩토링이 잘 수행되었다면 새로운 개발자(혹은 미래의 자신)가 기능 변경 요청을 받았을 때 아래의 3가지를 쉽게 해낼 수 있습니다.코드 위치 파악코드 수정 기능 테스트리팩토링으로 잘 설계된 코드는 이러한 핵심 과업을 쉽게 이행하는데 큰 도움이 됩니다.결론애자일 기법은 요구사항이라는 큰 덩어리를 작지만 동작하는 작은 기능으로 나누고 매 스프린트 마다 목표한 바를 착실히 정복해가는 방식이라고 할 수 있습니다.이 때 안전하게 기능을 수정 혹은 추가하기 위해서는 3개의 핵심 과업을 잘 수행해야 하는데요,코드로부터 도메인 파악하기(a.k.a. 코드 고고학)수정에 필요한 코드 파악하기수정된 코드 쉽게 검증하기 토스페이먼츠에서는 애자일하게 일하는 방법을 동료들과 함께 일 하면서 쉽게 터득할 수 있는 좋은 문화와 프로세스를 만들기 위해 서툰 실험을 계속하고 있습니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"6": {
		"createDate": "20231125",
		"title": "조금만 신경써서 초기 렌더링 빠르게 하기 (feat. JAM Stack)",
		"image": "https://wp.toss.tech/wp-content/uploads/2022/02/techblog-07-jam-stack.png",
		"content": "들어가면서SPA(Single Page Application) 구조로 웹 프론트엔드 애플리케이션이 개발되면서 초기 렌더링 속도는 프런트엔드 개발자에게 중요한 과제 중 하나가 되었습니다. 사용자 경험에 영향을 줄 수 있는 가장 큰 요소 중 하나가 바로 속도이기 때문입니다. 이번 개선은 Web Vitals 지표를 중심으로 측정했습니다.주어진 과제들과제 1. 번들 사이즈애플리케이션에 기능이 추가되면서 번들 사이즈가 커졌고 이로 인해 초기 렌더링이 늦어지는 문제가 발생하게 됩니다. 네트워크 비용을 줄이기 위해 Webpack으로 번들링했던 소스코드를 다시 적절한 단위로 코드 스플리팅(Code Splitting)을 하기도 하고 사용되지 않는 코드, 불필요한 코드들을 덜어내기 위한 트리 세이킹(Tree Shaking)을 위한 작업을 하기도 합니다.→ [SLASH 21] 이한 – JavaScript Bundle Diet이러한 노력을 하더라도 개선할 수 있는 부분엔 한계가 존재했습니다. 초기에 렌더링되는 index.html 자체가 비어있는 문서(Document)이기 때문에 스크립트가 실행되어 실제로 렌더링이 되기까지의 시간이 존재하기 때문입니다.과제 2. 렌더링 시점그렇다면 이제 렌더링 시점을 어떻게 앞당길 것인가에 대한 문제를 해결해야 됩니다. 사용자가 tosspayments.com 에 접근했을 때, 사용자가 최종적으로 볼 수 있는 화면을 서버에서 미리 그리고 그 화면을 브라우저에 전달해주면 초기 렌더링 시점이 앞당겨지지 않을까요?물론 인터랙션이 가능해지기 까지는 하이드레이트(Hydrate) 시간이 필요하지만, 사용자 입장에서는 우선 화면이 보여지는 것이 중요합니다. 초기에 렌더링 되는 index.html이 비어있는 문서가 아니라 무언가 렌더링되어 있는 문서라면 LCP(Largest Contentful Paint) 시점을 크게 앞당길 수 있을 것입니다.JAM Stack서론이 길었는데요, 토스페이먼츠에서 만들고 있는 일부 제품에서 SSR(Server Side Rendering)없이 초기 렌더링 속도를 개선해 보았습니다. 어떤 결과를 낳았으며 어떻게 개선했는지 이야기하고자 합니다.JAM Stack이란 JavaScript와 Markup에 해당하는 HTML, CSS 정적 리소스들을 활용하여 웹 애플리케이션을 구성하는 스택을 말합니다. 그리고 이 정적 리소스들을 CDN(Content Delivery Network)에 배포하여 서버 관리를 최소화 할 수 있습니다.토스페이먼츠에서는 AWS S3, CloundFront, Lambda@edge 를 사용하여 인프라를 운영하고 있습니다.→ JAM Stack에 대해 더 알아보기SSGStatic Site Generation이라는 개념인데요, 앱을 빌드하는 시점에 미리 그려두고 이를 서빙(serving)하는 방식을 말합니다. JAM Stack에서 정적 리소스를 생성하는 용도로 사용합니다.컴파일 단계에서 미리 그릴 수 있는 부분을 최대한 그려서 사용자에게 도달하는 최초 index.html 파일이 비어있지 않도록 합니다.미리 그릴 수 있다는 것은 말 그대로 컴파일 단계에서 리액트 코드를 읽어 HTML로 렌더링 할 수 있는 부분을 말합니다. 정적인 부분을 포함하여 인증이 필요하지 않은 데이터 또한 서버로부터 가져와 미리 그릴 수 있습니다.결과 (지표)구체적인 내용을 다루기에 앞서 어느 정도의 개선이 있었는지 먼저 소개하고자 합니다. 기대한 것 이상의 결과가 나와서 매우 즐거웠던 경험이었습니다.토스페이먼츠 상점관리자 초기 로딩 화면Lighthouse 지표before개선 하기 전 지표After개선 후 지표구체적인 지표 측정Chrome Browser에서 FP(First Paint)부터 LCP(Largest Contentful Paint)까지 걸린 시간을 측정해봤습니다.before(FP → LCP: 484ms)after(FP → LCP: 0ms)Large Contents에 해당하는 것을 일단 그려버리고 시작하니 0ms입니다.최대한 그릴 수 있는 영역을 미리 그림으로써 사용자는 흰 화면을 마주하지 않고 바로 제품을 만나는 것과 같은 느낌을 받을 수 있습니다.How?Next.js토스페이먼츠의 프런트엔드 애플리케이션은 Next.js 라는 프레임워크를 사용하고 있습니다. Next.js는 서버 사이드 렌더링은 물론이고 앞서 설명드린 Static Site Generate 또한 지원합니다. (Next.js Automiatic Static Optimization)Suspense우선 토스 대부분의 프런트엔드 애플리케이션 제품은 React의 Suspense를 통해 비동기를 제어하고 있으며 토스페이먼츠 제품 또한 예외가 아니었습니다. 이와 동시에 에러 핸들링 또한 ErrorBoundary를 통해 제어하면서 비동기 상황을 제어하고 있습니다.→ [SLASH 21] 박서진 – 프론트엔드 웹 서비스에서 우아하게 비동기 처리하기→ 선언적으로 에러 상황 제어하기이 Suspense를 Next.js와 함께 사용하기 위해선 약간의 추가 작업이 필요한데요, 앞서 설명드렸다시피 Next.js는 서버사이드 렌더링 또한 지원하는 프레임워크이기 때문에 Isomophic한 코드를 작성해야 합니다. 아쉽게도 Suspense는 서버사이드 렌더링이 지원되지 않습니다. (글을 작성하는 시점에 알파로 공개되어 있는 React 18에서 개선될 예정)그래서 다음과 같이 Suspense를 한번 감싸서 사용해줄 수 있습니다.import { useState, useEffect, Suspense as ReactSuspense } from 'react';\n\nexport function Suspense({ fallback, children }: ComponentProps<typeof ReactSuspense>) {\n  const [mounted, setMounted] = useState(false);\n\n  useEffect(() => {\n    setMounted(true);\n  }, []);\n\n  if (mounted) {\n    return <ReactSuspense fallback={fallback}>{children}</ReactSuspense>;\n  }\n  return <>{fallback}</>\n\n이렇게 수정된 Suspense로 제어하고 있는 컴포넌트를 SSG로 빌드하게 되면 fallback이 렌더링됩니다.다음과 같은 코드일 경우, SSG 시점엔 <Loading /> 컴포넌트만 그려지게 됩니다.function UserPage() {\n  return (\n    <Suspense fallback={<Loading />}> // <- Render!\n      <UserProfile />\n      <UserDetailInfo />\n    </Suspense>\n\n즉, 빌드 단계에서 SSG로 미리 그려주고자 했던 UserPage에는 Loading 컴포넌트만 렌더링 될 뿐, UserProfile , UserDetailInfo 컴포넌트는 전혀 렌더링 되지 않습니다. 미리 렌더링하는 것에 대한 이점을 전혀 얻지 못하게 되는 것입니다.번들 사이즈를 아무리 줄여도 사용자는 일단 로딩만 돌고 있는 흰 화면을 마주하게 되는 것입니다.컴포넌트 배치 되돌아보기우선 Suspense가 정말 필요한 컴포넌트인지, 레이아웃 영역인지 되돌아 볼 필요가 있습니다.정말 Suspense가 필요한 영역이라면 fallback 컴포넌트를 정의해줄 때 로딩 컴포넌트만 정의해주지 않는다면 어떨까요? API 응답이 돌아오고 결국 그려질 컴포넌트와 응답이 오지 않았을 경우 보여줄 이 fallback 컴포넌트를 최대한 비슷하게 구성해주는 겁니다. 그렇다면 컴파일 시점에 그릴 수 있는 영역이 늘어나지 않을까요?즉, 위와 같이 Loading 컴포넌트만 렌더링하지 않으려면 API 응답이 돌아왔을 때 그려져야 할 컴포넌트와 응답이 아직 돌아오지 않았을 때 보여줄 컴포넌트 두 벌이 최대한 비슷하게 구성되어 있어야 합니다.컴포넌트와 API를 가깝게처음 보셨던 화면에서는 총 16개의 API call이 존재합니다. 너무나 당연하게도 이 모든 API 응답은 제각각으로 올 것이고 모든 응답이 돌아오기를 기다렸다가 그려주는 것은 정말 낭비입니다.각각의 API들을 따로 격리시켜 서로의 렌더링을 block하지 않도록 합니다.데이터가 필요한 곳에서 가장 가까운 곳에서 API를 호출합니다. client caching이 이젠 너무나도 자연스럽기 때문에 이를 최대한 활용해줍니다.UserPage 컴포넌트의 구조를 다음과 같이 변경해 볼 수 있습니다.function UserPage() {\n  return (\n    <Layout>\n      <h1>사용자 정보</h1>\n      <dl>\n        <dt>이름</dt>\n        <Suspense fallback={<dd>Loading</dd>}>\n          <UserName />\n        </Suspense>\n      </dl>\n      <h2>사용자 상세 정보</h2>\n      <Suspense fallback={<div>Loading</div>}>\n        <UserDetailInfo />\n      </Suspense>\n    </Layout>\n  )\n}페이지 컴포넌트(UserPage) 전체를 감싸고 있던 Suspense 컴포넌트가 사라지고 비동기로 처리되는 영역이 좁게 정의가 되었습니다. 또한 비동기 처리 과정 중 노출되는 컴포넌트의 모습도 원래 보여질 컴포넌트와 비슷하게 정의해줬습니다.디자인이 필요한 영역이 늘었어요. API를 호출하고 기다리는 순간에 대해서도 디자인이 필요해요. 그대로 컴포넌트도 만들어줘야 하고 그만큼 손도 많이 갑니다. 하지만 서버 관리하는 비용보다 더 신경써줄 필요는 없다고 생각합니다.조금만 신경쓰더라도 많은 개선을 볼 수 있는 방법입니다.더 나아가기지난 Next.js Conf에서 공식적으로 React의 Server Component를 사용한 렌더링 방식이 공개되었습니다. React 18도 알파 단계이니 프런트엔드 애플리케이션을 개발하면서 성능 상 이점을 많이 챙길 수 있는 환경으로 뒤바꿈 될 것 같습니다. ISR 방식과 컴포넌트 단위의 캐싱이 적용되어 웹이 더 빨라질 수 있을 것이라 기대합니다.마무리초기 로딩 속도가 중요한 것은 비즈니스에도 영향을 미치기 때문입니다. web.dev에서 초기 로딩 속도를 개선하여 성과가 개선된 사례가 소개된 바 있습니다.(https://web.dev/vitals-business-impact/)당장에 SSR 도입이 쉽지 않은 상황이라면 SSG를 통한 초기 렌더링을 최적화 할 수 있습니다.토스 팀은 계속해서 초기 로딩 속도를 계속해서 개선 중입니다. 곧 있을 SLASH22에서는 ‘매달, 유저가 기다리는 시간을 2.3년씩 아낄 수 있는 초기 렌더링 개선기 (feat. SSR)’라는 제목으로 초기 렌더링 개선 경험을 공유할 예정이니 많은 관심 부탁드립니다.👉 토스페이먼츠 프런트엔드 챕터에 대해 더 알아보기감사합니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"7": {
		"createDate": "20231118",
		"title": "Kotlin으로 DSL 만들기: 반복적이고 지루한 REST Docs 벗어나기",
		"image": "https://wp.toss.tech/wp-content/uploads/2022/04/techblog-08-rest-docs.png",
		"content": "REST Docs 테스트 코드량을 70% 줄여주는 DSL 개발기읽는 데 걸리는 시간: 6분DSLDomain Specific Languages(DSL)은 코드의 내부 로직을 숨기고 재사용성을 올려줍니다. 어떤 경우는 비 개발자가 사용하도록 고안되는 경우도 있어서, 일반적인 프로그래밍 언어보다 훨씬 쉬운 사용성을 가집니다. 핵심은 해당 도메인을 아는 사람이면 누구나 쉽게 해당 도메인을 제어할 수 있도록 DSL을 제공하는것이 목적이며, 그렇기 때문에 프로그래밍 언어가 아닌 일반적인 언어에 가깝도록 호출 방식을 설계합니다. 때문에 DSL 호출 내부에서 어떤 로직이 작동하는지는 사용자가 알도록 할 필요가 없으며 훨씬 더 간결하고 빠르게 코드를 작성할 수 있습니다.Spring REST Docs, 더 쉽고 간결하게 쓸 수 없을까토스페이먼츠에서는 API docs를 REST Docs를 사용해서 작성할 수 있도록 권장하고 있습니다. docs를 작성하는 행위 자체에서부터 API를 통합테스트할 수 있다는 점이 매력적이며, 인터페이스의 의도치 않은 변경을 감지할 수 있다는 장점이 있습니다. 문제는 독스를 작성할 때마다 테스트 코드를 작성해줘야 하기 때문에 Swagger 보다 더 번거롭게 작업하게 된다는 문제가 있습니다.이 글에서는 DSL을 통해서 API 인터페이스의 안정성과 개발자의 생산성을 모두 가져갈 수 있는 방법을 소개합니다.REST Docs DSL먼저 기존의 작성법(AS-IS)과 DSL을 이용한 작성법(TO-BE)을 비교해보겠습니다.AS-IS.TO-BE.한 눈에 봐도 간결해보이지 않나요? AS-IS에서 볼 수 있듯, 기존의 작성법은 여러 문제가 있습니다.반복적인 코드 호출이 많음. 기존 작성법으로 작성할 때마다 생산성 저하를 느꼈습니다. API를 만드는 시간만큼이나 docs를 생성하는 시간이 걸린다니, 이것 참 비효율이지 않나요?코드가 장황하여 읽히지 않음. 인터페이스에 변화가 생기면 REST Docs 테스트 코드를 수정해야 하는데, 어떤 코드를 수정해야 하는지 빠르게 찾기가 어려웠습니다. 즉 해당 코드가 무엇을 수행하는지 한번에 읽기가 힘들고, 이 코드 수행 결과가 어떤 docs를 만들어낼지 단번에 떠올리기 어렵다는 단점이 있었습니다.첫 번째 단점은 기존의 다른 코드로부터 복붙으로 시간을 좀 줄여낼 수는 있었지만, 두 번째 단점은 참 신경 쓰였습니다. 저는 JSON과 같은 간결한 구조로부터 docs를 테스트하는 코드가 만들어지길 원했습니다.Kotlin으로 DSL 만들기다행히도 Kotlin은 여러 함수 선언 방식이 존재하여서, 이런 문제를 풀기에 매우 좋습니다. Kotlin의 테스트 코드 라이브러리인 Kotest와 MockK이 대표적인 사례라고 생각합니다.infix 함수Infix Notation (kotlinlang.org)잘 만들어진 DSL은 인간의 자연어를 사용하듯이 자연스럽게 쓰고 읽힐 수 있어야 한다고 생각합니다. Kotlin의 infix notation은 이 목표를 달성하기에 최적의 도구입니다.\"data.businessId\" type NUMBER는 \"data.businessId\".type(NUMBER)와 동일한 효과를 낳습니다.infix fun String.type(                    // (1)\n    docsFieldType: DocsFieldType\n): Field {                                // (2)\n    ...                                   // (3)\n}(1):infix notation으로 해당 함수를 선언해줍니다.type이라는 함수는 String을 receiver로 받는 함수입니다.파라미터는 docsFieldType 하나만 받습니다 (DocsFieldType는 아래에서 서술합니다.)(2): 원래 restdocs가 제공하던 FieldDescriptor를 유연하게 다루기 위해 Field라는 Wrapper 클래스를 정의합니다.(3): 원래의 RestDocs를 만들던 동작을 수행합니다infix 함수를 사용할때는 제한사항이 있습니다.호출할때는 receiver와 parameter가 명시적으로 있어야 함 (this로 암시적인 전달 불가능)parameter는 하나여야 함 (default value도 지정할 수 없음)그래야만 \"data\" type OBJECT 처럼 간결한 구조를 만들어 낼 수 있기 때문입니다.DocsFieldTypeREST Docs에서는 응답, 요청 필드의 type을 JsonFieldType으로서 구분합니다.여기에 저는 자주 사용하는 format인 Date, DateTime을 쉽게 정의할 방법을 찾고 싶었고, enum class도 간단히 전달하여 어떤 필드가 사용될 수 있는지 docs에 쉽게 표기하고 싶었습니다. date, datetime, enum은 모두 JsonFieldType.STRING이지만 format과 sample이 다르게 표시될 필요가 있는 특이 케이스이기 때문입니다.이런 식으로 정의한다면 아래 예시와 같이 간단하게 Field를 생성해내면서 DocsFieldType을 정의해낼 수 있습니다.\"data\" type OBJECT\n\"id\" type NUMBER\n\"createdAt\" type DATETIMEDocsFieldType - enum다만 enum을 정의하고 싶을때는 조금 디테일이 필요합니다.\"companyType\" type STRING example CompanyType::class로도 선언할 수는 있지만 매번 example을 호출해주는 건 조금 귀찮습니다. 어차피 enum이 string이라는건 누구나 다 아는 사실인데 두 함수 호출을 나눠야 할까요?\"companyType\" type ENUM(CompanyType::class)훨씬 간결해졌습니다.다음과 같이 DocsFieldType을 확장한 sealedSubclass를 만든다면 위와 같은 dsl 작성이 가능합니다.data class ENUM<T : Enum<T>>(val enums: Collection<T>) : DocsFieldType(JsonFieldType.STRING) {\n  constructor(clazz: KClass<T>) : this(clazz.java.enumConstants.asList())   // (1)\n}(1): secondary constructor 덕분에 모든 enum값이 아니라 특정 조건에 맞는 enum 값을 collection으로 넘길수도 있습니다.ex) 개인사업자에 해당하는 companyType만 해당 필드에 존재할 수 있을 때 \"individualCompanyType\" type ENUM(CompanyType.values().filter { it.isIndividual() })이로써 type infix 함수는 아래와 같이 완성할 수 있습니다.infix fun String.type(docsFieldType: DocsFieldType): Field {\n    val field = createField(this, docsFieldType.type)\n    when (docsFieldType) {\n        is DATE -> field formattedAs RestDocsUtils.DATE_FORMAT\n        is DATETIME -> field formattedAs RestDocsUtils.DATETIME_FORMAT\n        else -> {}\n    }\n    return field\n}\n\ninfix fun <T : Enum<T>> String.type(enumFieldType: ENUM<T>): Field {\n    val field = createField(this, JsonFieldType.STRING, false)\n    field.format = EnumFormattingUtils.enumFormat(enumFieldType.enums)\n    return field\n}\n\nprivate fun createField(value: String, type: JsonFieldType, optional: Boolean): Field {\n    val descriptor = PayloadDocumentation.fieldWithPath(value)\n        .type(type)\n        .attributes(RestDocsUtils.emptySample(), RestDocsUtils.emptyFormat(), RestDocsUtils.emptyDefaultValue())\n        .description(\"\")\n\n    if (optional) descriptor.optional()\n\n    return Field(descriptor)\n}\n\nField 클래스에서 DSL 확장하기이제 좀 더 욕심을 내봅시다. 위 예시처럼 얼마든지 함수 호출을 chaining할 수 있습니다.어떤가요? 괄호로 계속 호출하는 것보다 좀 더 직관적이지 않나요?type이라는 infix function이 Field를 반환할 수 있도록 했으니, Field에서 더 많은 DSL을 호출하도록 확장할 수 있게 되었습니다.open class Field(\n    val descriptor: FieldDescriptor,\n) {\n    val isIgnored: Boolean = descriptor.isIgnored\n    val isOptional: Boolean = descriptor.isOptional\n\n    protected open var default: String\n        get() = descriptor.attributes.getOrDefault(RestDocsAttributeKeys.KEY_DEFAULT_VALUE, \"\") as String\n        set(value) {\n            descriptor.attributes(RestDocsUtils.defaultValue(value))\n        }\n\n    protected open var format: String\n        get() = descriptor.attributes.getOrDefault(RestDocsAttributeKeys.KEY_FORMAT, \"\") as String\n        set(value) {\n            descriptor.attributes(RestDocsUtils.customFormat(value))\n        }\n\n    protected open var sample: String\n        get() = descriptor.attributes.getOrDefault(RestDocsAttributeKeys.KEY_SAMPLE, \"\") as String\n        set(value) {\n            descriptor.attributes(RestDocsUtils.customSample(value))\n        }\n\n  \topen infix fun means(value: String): Field {\n        return description(value)\n    }\n\n    open infix fun attributes(block: Field.() -> Unit): Field {\n        block()\n        return this\n    }\n\n    open infix fun withDefaultValue(value: String): Field {\n        this.default = value\n        return this\n    }\n\n    open infix fun formattedAs(value: String): Field {\n        this.format = value\n        return this\n    }\n\n    open infix fun example(value: String): Field {\n        this.sample = value\n        return this\n    }\n\n    open infix fun isOptional(value: Boolean): Field {\n        if (value) descriptor.optional()\n        return this\n    }\n\n    open infix fun isIgnored(value: Boolean): Field {\n        if (value) descriptor.ignored()\n        return this\n    }\n}\n\n이렇게 얼마든지 코드를 확장해나갈 수 있을뿐더러, 해당 프로젝트에서 사용하는 REST Docs snippet의 attribute를 코드 상으로 좀 더 명확하게 정의할 수 있게 되었습니다.마무리이 글은 REST Docs의 반복적인 코드를 제거하고, docs의 생성이라는 본래의 목적을 달성하고자 기존 MockMvc 테스트코드 작성법에서 벗어나, REST Docs DSL을 만드는 방식으로 문제를 해결하고자 했습니다.우리가 흔히 쓰는 gradle configuration 작성 방식인 build.gradle.kts 또한 org.gradle.kotlin.dsl에서 그 선언 방식을 찾아볼 수 있고, MockK이나 Kotest에서도 다양한 방식으로 Kotlin의 장점을 최대한 끌어낸 모습을 확인할 수 있습니다.build.gradle.kts (https://github.com/gradle/kotlin-dsl-samples)MockK의 every(https://mockk.io/#dsl-examples),Kotest의 여러 Testing Styles(https://kotest.io/docs/framework/testing-styles.html)혹시나 여러분도 반복적인 작업을 일일히 복붙으로 하고 있다면 여러분의 팀만을 위한 DSL을 만들어보는 건 어떨까요?이 REST Docs DSL은 토스페이먼츠 *엔지니어링 데이에 장태영(Server Developer, taeyoung.jang@tosspayments.com)님과 함께 만들었습니다.토스페이먼츠에서는 매주 목요일에 엔지니어링 데이를 진행하고 있어요. 이 시간에는 평소 업무에 병목이 되는 문제들을 해결하거나, 인프라를 개선하는 등의 작업을 진행합니다.재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"8": {
		"createDate": "20231110",
		"title": "에러 핸들링을 다른 클래스에게 위임하기 (Kotlin 100% 활용)",
		"image": "https://wp.toss.tech/wp-content/uploads/2022/05/techblog-09-error-handling.png",
		"content": "TL;DRResult를 이해한다면, MSA 환경에서 에러가 전파되지 않도록 막을 수 있습니다.runCatching과 Result를 사용하면 에러 핸들링을 클라이언트에게 위임할 수 있습니다.예제: 로그인 요청을 전달하는 서비스 흐름에서 에러 처리하기아래와 같은 서비스 호출 흐름이 있다고 가정해보겠습니다.Server A 입장에서는 Server B에서 발생하는 에러 처리를 해야하는 고민에 빠집니다.API를 호출하는 코드에서 API의 에러 응답에 따른 비즈니스 로직을 다르게 가져가고 싶은 경우가 있습니다. 예를 들어 위 사례에서 비밀번호가 틀리거나 이메일 주소가 틀린 경우 이 에러를 캐치해서 다른 메세지를 던지고 싶을 수 있고, 어떤 코드에서는 그 에러를 무시하고 다른 로직을 수행하고 싶을 수 있습니다.에러 처리를 API Client 단에서 하지 않고 다른 클래스에 위임을 하고 싶은 이런 경우에는 어떤 방법을 사용할 수 있을지 아래 코드 예시로 알아보겠습니다.// API client\n@FeignClient\ninternal interface LoginApi {\n  @PostMapping\n  fun login(\n    @RequestBody request: LoginRequestDto\n  ): OtherServiceResponse<LoginResponseDto>\n}\n\n@Component\nclass LoginApiClient internal constructor(\n  private val loginApi: LoginApi\n) {\n  fun login(request: LoginRequestDto): LoginResult {\n    return loginApi.login(request).result.toResult()\n  }\n}\n\n@Service\nclass LoginService(\n  private val loginApiClient: LoginApiClient\n) {\n  fun login(id: String, pw: String): LoginResult {\n    return try {\n      loginApiClient.login(LoginRequestDto(id, pw))\n    } catch {\n      // 에러 핸들링\n    }\n  }\n}\n\n이 경우에 아래와 같은 두 케이스를 해결하고 싶어집니다.이 API를 사용하는 쪽(ex. LoginService)에서 에러 핸들링을 강제하고 싶습니다.API 호출 로직마다 에러 핸들링을 다른 방식으로 가져가게 하고 싶습니다.LoginService가 아닌 다른 호출 로직에서는 에러를 다르게 처리하고 싶을 수 있습니다.위 고민을 해결할 방법이 있습니다. 바로 Result입니다.@Component\nclass LoginApiClient internal constructor(\n  private val loginApi: LoginApi\n) {\n  fun login(request: LoginRequestDto): Result<LoginResult> {\n    return runCatching {\n      loginApi.login(request).result.toResult()\n    }\n  }\n}\n\n@Service\nclass LoginService(\n  private val loginApiClient: LoginApiClient\n) {\n  fun login(id: String, pw: String): LoginResult {\n    return loginApiClient.login(LoginRequestDto(id, pw))\n      .onFailure {\n        // 에러 핸들링\n      }\n  }\n}코틀린의 runCatching💡 이미 runCatching을 잘 사용하고 있다면 넘겨도 좋습니다.위 코드를 이해하기에 앞서서 runCatching을 알아둘 필요가 있습니다. 코틀린은 물론 자바의 try ... catch를 동일하게 지원하지만 이와는 조금 다른 방법으로 에러 핸들링을 할 수도 있습니다.예제아래 요구사항이 있다고 가정합시다.LoginApiClient 호출 시 LoginException이 발생했는데,errorCode가 INVALID_PASSWORD 인 경우 예외를 발생시키지 않고 null을 반환한다.그 외 모든 에러 상황에서는 예외를 발생시킨다.try ... catch를 사용했을때try {\n  loginApiClient.login(request)\n} catch (e: LoginException) {\n  if (e.errorCode == \"INVALID_PASSWORD\") {\n    return null\n  } else {\n    throw e\n  }\n}Java에서 위와 같이 작성하는 코드를 runCatching을 사용하면 아래처럼 표현할 수 있습니다.runCatching을 사용했을 때return runCatching {\n  loginApiClient.login(request)\n}.onFailure { e ->\n  if (e.errorCode != \"INVALID_PASSWORD\") throw e\n}.getOrNull()kotlin.runCatching@InlineOnly\n@SinceKotlin(\"1.3\")\npublic inline fun <R> runCatching(block: () -> R): Result<R> {\n  return try {\n    Result.success(block())\n  } catch (e: Throwable) {\n    Result.failure(e)\n  }\n}try..catch 로직을 그대로 사용하지만 Result로 감싸서 반환하는 것을 알 수 있습니다.에러가 발생하지 않았을 때에는 Result.success 반환에러가 발생했을 때에는 Result.failure 반환Result가 뭔가요?Result가 무엇인지 알아보기 위해서 Kotlin 1.3 표준 라이브러리의 코드를 살펴봅시다.@SinceKotlin(\"1.3\")\n@JvmInline\npublic value class Result<out T> @PublishedApi internal constructor(\n  @PublishedApi\n  internal val value: Any?\n) : Serializable {\n\n  public val isSuccess: Boolean get() = value !is Failure\n\n  public val isFailure: Boolean get() = value is Failure\n\n  /* ... */\n\n  public companion object {\n    @Suppress(\"INAPPLICABLE_JVM_NAME\")\n    @InlineOnly\n    @JvmName(\"success\")\n    public inline fun <T> success(value: T): Result<T> =\n      Result(value)\n\n    @Suppress(\"INAPPLICABLE_JVM_NAME\")\n    @InlineOnly\n    @JvmName(\"failure\")\n    public inline fun <T> failure(exception: Throwable): Result<T> =\n      Result(createFailure(exception))\n  }\n\n  internal class Failure(\n    @JvmField\n    val exception: Throwable\n  ) : Serializable {\n    /* ... */\n  }\n}\n\n즉, Result의 value는성공일 경우 T를 타입으로 하는 값을 가지게 되고실패일 경우는 Failure를 wrapper class로 하는 exception을 값으로 가지게 됩니다.Result가 제공하는 함수들은 다음과 같습니다.inline fun <T> Result<T>.getOrThrow(): T\n\ninline fun <R, T : R> Result<T>.getOrElse(\n  onFailure: (exception: Throwable) -> R\n): R\n\ninline fun <R, T : R> Result<T>.getOrDefault(defaultValue: R): R\n\ninline fun <R, T> Result<T>.fold(\n  onSuccess: (value: T) -> R,\n  onFailure: (exception: Throwable) -> R\n): R\n\ninline fun <R, T> Result<T>.map(transform: (value: T) -> R): Result<R>\n\nfun <R, T> Result<T>.mapCatching(transform: (value: T) -> R): Result<R>\n\ninline fun <R, T : R> Result<T>.recover(transform: (exception: Throwable) -> R): Result<R>\n\ninline fun <T> Result<T>.onFailure(action: (exception: Throwable) -> Unit): Result<T>\n\ninline fun <T> Result<T>.onSuccess(action: (value: T) -> Unit): Result<T\n\nResult 사용 예시runCatching은 Result<T>를 반환하게 되는데, Result가 제공하는 함수를 이용해서 다양하게 활용할 수 있습니다.에러를 무시하고 null 반환val response = runCatching {\n  login()\n}.getOrNull()기본값 반환val response = runCatching {\n  login()\n}.getOrDefault(emptyList())에러 발생 시 다른 동작 수행val response = runCatching {\n  login()\n}.getOrElse { ex ->\n  logger.warn(ex) { \"에러 발생\" }\n\n  // 에러를 던지고 싶다면\n  throw ex\n}에러가 발생한 경우에만 해당 에러 객체 반환val exception = runCatching {\n  login()\n}.exceptionOrNull()\n\n// 위에서 받은 에러로 로직 수행\nwhen (exception) {\n  /* ... */\n}에러가 발생하는지 아닌지만 확인하고 싶을 때에도 유용할 수 있습니다.val isValidCredential = runCatching { tryLogin() }.exceptionOrNull() != null성공/에러 시 각각 특정 동작 수행 후 에러 던지기val response = runCatching {\n  login()\n}.onSuccess {\n  logger.info(\"성공!\")\n}.onFailure {\n  logger.info(\"실패!\")\n}.getOrThrow()runCatching으로 try .. finally 구현하기runCatching {\n  request()\n}.also {\n  doSomething()\n}.getOrThrow()Result를 사용해서 예외 처리를 다른 클래스에 위임하기runCatching을 사용하면 Result가 제공하는 다양한 함수의 편의에 기댈 수 있다는 것을 배웠습니다.Result에 대한 처리를 즉시 하지 않고 함수의 반환 값으로 반환하게 된다면, Result에 대한 핸들링을 다른 클래스에 위임할 수도 있습니다.LoginApiClient@Component\nclass LoginApiClient internal constructor(\n  private val loginApi: LoginApi\n) {\n  fun login(request: LoginRequestDto): Result<LoginResult> {\n    return runCatching {\n      loginApi.login(request).result.toResult()\n    }\n  }\n}\n\nResult를 반환하여 다른 클래스가 에러 핸들링을 하도록 위임합니다.LoginService@Service\nclass LoginService(\n  private val loginApiClient: LoginApiClient\n) {\n  fun login(id: String, pw: String): LoginResult? {\n    return loginApiClient.login(LoginRequestDto(id, pw))\n      .getOrNull()\n  }\n}\n\n에러가 발생한 경우 에러를 무시하고 기본값으로 null을 반환합니다.하지만 아래처럼 다른 컴포넌트에서는 에러를 핸들링하고 싶을 수도 있습니다.PasswordChangeService@Component\nclass PasswordChangeService(\n  private val loginApiClient: LoginApiClient,\n  private val errorStatusWriter: ErrorStatusWriter,\n  private val passwordChanger: PasswordChanger\n) {\n  fun change() {\n    loginApiClient.login(request)\n      .onFailure { exception ->\n        errorStatusWriter.write(exception)    // (1)\n      }.onSuccess { loginResult ->\n        passwordChanger.change(loginResult)   // (2)\n      }.getOrThrow()                          // (3)\n  }\n}[1] 에러가 발생한 경우 에러를 기록합니다.[2] 성공한 경우 해당 값을 받아서 다른 컴포넌트를 호출합니다.→ [1], [2]번 두 케이스는 배타적이고 동시에 일어날 수 없습니다.[3] 그리고 에러인 경우 예외를 발생시킵니다.결론정리하자면 Result(runCatching)는 다음의 용도에서 사용할 수 있습니다.외부 서비스에 의존하는 로직이라 예외 발생 가능성이 빈번한 컴포넌트해당 컴포넌트에서 에러가 발생할 수 있다는 것을 클라이언트에게 알려주고 싶을 때, 에러 핸들링을 다른 컴포넌트에 강제하고 위임하고 싶을 때try ... catch를 쓰고 싶지 않을 때재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"9": {
		"createDate": "20231102",
		"title": "테스트 의존성 관리로 높은 품질의 테스트 코드 유지하기",
		"image": "https://wp.toss.tech/wp-content/uploads/2022/06/techblog-10-test-code.png",
		"content": "테스트 코드는 애플리케이션 코드 못지 않게 높은 품질을 유지해야 합니다.낮은 품질(이해하기 어려운 코드, 여기저기 깨져있는 테스트)의 테스트는 유지보수가 어렵고 기술부채에 못지 않은 부채로 다가옵니다.그래서 테스트 코드의 높은 품질을 유지하기 위해 다양한 Builder, Helper 클래스들이 나오게 되고, 테스트 전용으로 의존성을 추가하기도 합니다. 하지만 이 또한 관리의 대상이며 제대로 관리하지 않으면 중복 코드와 얼기설기 얽힌 의존성 지옥을 맛보게 됩니다.이 포스트에서는 Gradle의 java-test-fixtures 플러그인을 사용하여 위 문제를 해결하는 방법에 대해 설명합니다.TL;DRGradle의 java-test-fixtures 플러그인을 사용하면 테스트용으로 작성한 Builder, Helper 클래스 등등을 다른 모듈과 공유할 수 있습니다.추가적으로 해당 모듈의 테스트 전용 의존성까지 전파시킬 수 있어 각 모듈마다 불필요한 테스트 전용 의존성들을 일일이 추가할 필요가 사라집니다.프로젝트 구조예제를 이해하기 쉽게 하기 위해 프로젝트 구조(멀티 모듈)를 가정하고 이야기를 진행하겠습니다.domain 모듈: 핵심 비즈니스 로직에만 관심이 있는 모듈, 외부(써드파티 라이브러리, DB, HTTP 등등)에 의존하지 않고 온전히 비즈니스 로직에만 관심을 갖고 있는 모듈로써 어떠한 의존성도 가지지 않습니다.db 모듈: 데이터의 CRUD(저장, 조회, 수정, 삭제)에만 관심이 있는 모듈, 클라이언트의 요구사항을 처리하기 위해 domain 모듈에 의존(implementation)하고 있습니다.이미지 출처: Gradle Docs// db 모듈의 build.gradle.kts\ndependencies {\n    implementation(project(\":domain\"))\n    // 기타 디펜던시들...\n}application 모듈: 클라이언트의 요청을 받아 처리하는 모듈, 클라이언트의 요구사항을 처리하기 위해 domain 모듈에 의존(implementation)하고 있으며, application 모듈에 main 함수가 존재하기 때문에 데이터 조작(저장, 조회 등등)을 위해 db 모듈에도 의존(runtimeOnly)하고 있습니다.이미지 출처: Gradle Docs// application 모듈의 build.gradle.kts\ndependencies {\n    implementation(project(\":domain\"))\n    runtimeOnly(project(\":db\"))\n    // 기타 디펜던시들...\n}테스트 전용으로 작성한 클래스를 다른 모듈에게 노출시키기domain 모듈에 아래와 같은 객체가 있다고 가정해보겠습니다.class Order(\n    val id: String,\n    val description: String,\n    val amount: Long\n)테스트에서 위 클래스를 사용해야할 때 객체를 생성하려고 생각하면 매우 번거로워집니다. (공감이 되지 않는다면 파라미터가 10개 정도 된다고 생각해보면 됩니다.)이 때 모든 파라미터에 기본값을 넣는 절충안도 존재하는데, 객체의 필수값이 기본값으로 채워진 채 객체가 생성되면 불안정하게 동작할 수 있습니다. 누군가의 실수로 프로덕션에서 객체의 필수값 중 일부가 기본값으로 생성된다면 의도치 않은 동작을 하게 될 수도 있기 때문입니다.따라서 테스트에서 사용할 목적으로 디폴트 값이 들어간 빌더 객체를 만들게 됩니다.참고로 IntelliJ IDEA에서 코틀린 클래스의 빌더를 만들어주는 플러그인은 kotlin-builder-generator를 사용하면 손 쉽게 만들 수 있습니다.data class OrderBuilder(\n    val id: String = \"\",\n    val description: String = \"\",\n    val amount: Long = 0L\n) {\n    fun build(): Order {\n        return Order(\n            id = id,\n            description = description,\n            amount = amount\n        )\n    }\n}하지만 빌더는 테스트에서만 사용해야하기 때문에 domain/src/test 디렉토리 밑에 생성해야합니다. test가 아닌 main 디렉토리 밑에 존재하게 되면 프로덕션 코드에서 누가 해당 빌더로 온전치 않은 상태의 객체를 생성하고 사용하는 실수를 할 수 있기 때문입니다.이런 Builder나 Helper 같이 테스트 전용으로 만든 클래스들을 해당 클래스가 존재하는 모듈(domain 모듈)이 아닌 해당 모듈을 의존하고 있는 다른 모듈(domain 모듈에 의존하고 있는 application, db 모듈)의 테스트에서 사용하고 싶다는 니즈가 생겼다고 가정해보겠습니다.하지만 application과 db 모듈에서 domain 모듈에 의존하고 있다고 할지라도 각 모듈의 테스트에서는 OrderBuilder를 import 할 수 없습니다.build된 jar 파일의 압축을 해제했을 때 나오는 결과물을 보면 main 디렉토리 밑에 있는 Order 클래스는 포함하고 있지만, test 디렉토리 밑에 있는 OrderBuilder 클래스는 포함하고 있지 않기 때문입니다.어떻게 생각해보면 당연한 결과입니다.domain 모듈을 테스트하는데 필요한 정보들은 프로덕션 코드에서는 필요가 없고, 그렇기 때문에 굳이 불필요하게 테스트 전용 클래스들까지 포함시킬 필요는 없기 때문입니다.이제 문제를 해결하기 위한 간단한 방법 두 가지를 떠올리게 됩니다.각 모듈의 test 디렉토리에 빌더를 복사/붙여넣기 합니다. 하지만 이는 코드의 중복을 유발하며 Order 클래스의 변경사항이 생겼을 때 각 모듈에 존재하는 OrderBuilder 클래스를 각각 수정해야한다는 번거로움이 존재합니다.Builder/Helper를 모아놓은 별도의 test-data 같은 테스트 전용 모듈을 만들고, 각 모듈에서 test-data 클래스에 의존(testImplementation)하게 만듭니다.// application/db 모듈의 build.gradle.kts\ndependencies {\n    // 기타 디펜던시들...\n    testImplementation(project(\":test-data\"))\n}하지만 이는 실제 소스코드(Order는 domain 모듈에 존재)와 거리가 멀어지게 만들어(OrderBuilder는 test-data 모듈에 존재) 응집도가 떨어지는 모듈이 나오게 됩니다.또한 테스트 전용임에도 불구하고 test-data 모듈의 클래스들을 외부에 노출시켜야하기 때문에 test 디렉토리가 아닌 main 디렉토리에 둬야 하는 점도 약간의 혼란(’main 디렉토리에 있으니까 프로덕션 레벨에서 사용하는 건가…?’ 하는 정도의)을 유발할 수 있습니다.둘 다 좋은 방법은 아니라는 생각이 듭니다. 이 문제를 해결하기 위한 빛과 소금과 같은 존재가 있습니다.구세주: java-test-fixtures 플러그인Gradle에는 이런 문제를 해결하고자 java-test-fixtures 플러그인이 존재합니다.우선 외부에 노출시키고자 하는 Builder나 Helper 클래스가 존재하는 domain 모듈의 build.gradle.kts 파일에 플러그인을 추가해주고 프로젝트를 reload 하면 됩니다.// domain 모듈의 build.gradle.kts\nplugins {\n    // 기타 플러그인들...\n    `java-test-fixtures`\n}java-test-fixtures 플러그인이 적용된 모듈에서 디렉토리를 생성하려고 하면 IntelliJ IDEA에서는 testFixtures 디렉토리가 자동완성 됩니다.그럼 아까 생성했던 OrderBuilder 클래스는 test가 아닌 testFixtures 디렉토리로 이동시켜준 후 build를 했을 때 수행되는 Gradle Task들을 보게 되면 testFixture 관련된 task가 추가된 걸 알 수 있습니다../gradlew :domain:build\n\n...\n> Task :domain:compileTestFixturesKotlin\n> Task :domain:compileTestFixturesJava NO-SOURCE\n> Task :domain:processTestFixturesResources NO-SOURCE\n> Task :domain:testFixturesClasses UP-TO-DATE\n> Task :domain:testFixturesJar\n\n그리고 빌드된 결과물을 보면 test-fixtures.jar가 추가된 걸 볼 수 있습니다.plain.jar는 plain에, test-fixtures.jar는 test에 각각 풀었는데 OrderBuilder는 test에 존재하는 걸 보니 test-fixtures.jar에 존재한다는 걸 알 수 있습니다.여기서 또 java-test-fixtures 플러그인의 장점이 나오게 되는데 다른 모듈에서 불필요하게 여기는 클래스들(test 디렉토리에 있는 @Test 어노테이션이 붙은 테스트 코드들 등등)은 노출되지 않고, 필요한 클래스들(testFixtures 디렉토리에 있는 Helper나 Builder 클래스 등등)만 노출된다는 점입니다.하지만 이렇게 했다고 해서 아직 application이나 db 모듈에서 OrderBuilder를 import 할 수 있는 건 아닙니다. application과 db 모듈에서는 plain.jar에 의존하고 있는 것이지, test-fixtures.jar에 의존하고 있는 건 아니기 때문입니다.따라서 application과 db 모듈에서 test-fixtures.jar에 의존하도록 각 모듈의 build.gradle.kts에 추가해줘야합니다.// application/db 모듈의 build.gradle.kts\ndependencies {\n    implementation(project(\":domain\"))\n    testImplementation(testFixtures(project(\":domain\")))\n    // 기타 디펜던시들...\n}위와 같이 의존성을 추가해줘야 비로소 application과 db 모듈의 테스트 코드에서도 domain 모듈의 testFixtures에 존재하는 OrderBuilder를 사용할 수 있게 됩니다.이해하기 쉽게 모듈 간의 디렉토리 관계를 좀 더 세분화해서 표현해보았습니다.테스트 전용으로 추가한 의존성을 다른 모듈에게 노출시키기db 모듈의 통합테스트를 위해 인메모리 DB인 H2를 테스트 전용으로 의존성을 추가했다고 가정해보겠습니다.이미지 출처: Gradle Docs// db 모듈의 build.gradle.kts\ndependencies {\n    // 기타 디펜던시들...\n    testRuntimeOnly(\"com.h2database:h2\")\n}이 상태에서 db 모듈의 통합테스트를 돌리게 되면 H2 DB를 사용하여 실제 DB와 격리된 환경에서 테스트가 돌아가는 것을 볼 수 있습니다.그리고 application 모듈은 아래와 같이 db 모듈에 의존하고 있기 때문에 통합테스트를 작성할 때도 인메모리 DB를 쓸 것이라 희망하게 되는데 실제로 테스트를 짜고 돌려보면 그렇지 않습니다.// application 모듈의 build.gradle.kts\ndependencies {\n    // 기타 디펜던시들...\n    runtimeOnly(project(\":db\"))\n}gradle 모듈의 디펜던시를 보게 되면 db 모듈의 testRuntimeClasspath에는 H2가 존재하지만, application 모듈의 testRuntimeClasspath에 존재하는 db 모듈에는 H2가 존재하지 않기 때문입니다.이 때도 application 모듈의 build.gradle.kts에 H2를 의존성으로 추가하는 방법이 있겠지만 관심사 문제가 있습니다. application 모듈의 관심사는 ‘어떻게 클라이언트와 커뮤니케이션해서 요구사항을 만족시킬 것인가?’이지 세부적인 내용(’저장소는 무엇을 쓸까? 데이터는 어디서 저장하고 어떻게 불러올까?’ 같은)은 관심사가 아닙니다. 따라서 H2를 직접적으로 의존성을 추가하는 순간 관심사 분리가 제대로 되지 않게 됩니다.이 문제를 해결하기 위해 또 우리의 구세주 java-test-fixtures 플러그인이 필요합니다.testFixturesComplieClasspath와 testFixturesRuntimeClasspath우선 외부에 테스트 전용 의존성(H2)을 노출시키고 싶은 db 모듈에 java-test-fixtures 플러그인을 추가하고, testRuntimeOnly로 추가했던 H2 의존성을 testFixturesRuntimeOnly로 변경해줘야 합니다.// db 모듈의 build.gradle.kts\nplugins {\n    // 기타 플러그인들...\n    `java-test-fixtures`\n}\n\ndependencies {\n    // 기타 디펜던시들...\n    testFixturesRuntimeOnly(\"com.h2database:h2\")\n}그리고 나서 다시 db 모듈의 디펜더시를 보면 기존에 보지 못했던 testFixturesCompileClasspath와 testFixturesRuntimeClasspath가 추가된 게 보입니다.사실 두 가지 클래스패스는 java-test-fixtures 플러그인을 추가하기만 해도 추가되는 클래스패스입니다.여기서 눈여겨봐야할 것은 기존에는 testRuntimeClasspath에만 존재하던 H2 의존성이 testFixturesRuntimeClasspath에도 추가된 점입니다.이에 대한 해답은 java-test-fixtures 플러그인 문서를 보다보면 아래와 같은 내용에 나오게 됩니다.Test fixtures are configured so that: • they can see the main source set classes • test sources can see the test fixtures classes두 번째로 나와있는 테스트 소스(test 디렉토리에 있는 내용들)에서 test fixture(testFixtures 디렉토리에 있는 내용들)에 있는 내용을 참조(can see)할 수 있도록 구성된다는 내용이 핵심입니다.따라서 testFixturesRuntimeOnly로만 추가(testFixturesRuntimeClassPath)했지만 testRuntimeOnly로도 추가된 것과 동일한 효과(testRuntimeClasspath에 추가된 효과)를 같이 보게 됩니다. 따라서 db 모듈의 통합테스트를 돌렸을 때는 여전히 H2 DB를 사용하게 됩니다.하지만 H2를 db 모듈에 testFixturesRuntimeClasspath에 추가했지만, 여전히 application 모듈의 testRuntimeClasspath를 보면 아직도 db 모듈에는 H2 의존성이 추가되지 않은 모습을 볼 수 있습니다.그 이유는 application 모듈의 build.gradle.kts를 보면 알 수 있습니다.// application 모듈의 build.gradle.kts\ndependencies {\n    // 기타 디펜던시들...\n    runtimeOnly(project(\":db\"))\n}이미지 출처: Gradle Docs바로 정답은 runtimeOnly 키워드에 있습니다.runtimeOnly로 추가한 디펜던시는 testRuntimeClasspath에도 추가됩니다. (물론 runtimeClasspath에도 추가됩니다.)하지만 testRuntimeClasspath에 추가된 의존성은 외부 모듈에 노출되지 않는다는 특성이 있습니다.따라서 우리는 db 모듈의 testRuntimeClasspath가 아닌 testFixturesRuntimeClasspath에 추가된 의존성들에 주목해야하며 해당 의존성들이 추가되도록 application 모듈의 build.gradle.kts를 수정해야 합니다.// application 모듈의 build.gradle.kts\ndependencies {\n    // 기타 디펜던시들...\n    runtimeOnly(project(\":db\"))\n    testRuntimeOnly(testFixtures(project(\":db\")))\n}마지막 부분이 db 모듈의 testFixturesRuntimeClasspath에 있는 의존성을 testRuntimeOnly로 추가(testRuntimeClasspath에 추가)하는 내용입니다.이제 application 모듈의 testRuntimeClasspath에도 db 모듈의 testFixutresRuntimeClasspath에 있는 H2 의존성이 추가된 걸 볼 수 있습니다.이 상태에서 application 모듈의 통합테스트를 돌리더라도 H2 DB를 사용하는 걸 볼 수 있습니다.결론테스트 코드는 실제 프로덕션에 영향을 미치지 않으므로 신경을 덜 쓰기 마련입니다. 그러다보면 중복이 난무하고 관심사 분리도 제대로 되지 않고 의존성 지옥에 빠지기 십상입니다. 하지만 테스트 코드는 우리의 소프트웨어를 좀 더 나은 설계로 유도하며 안정감도 주기 때문에 품질을 관리해야하는 소프트웨어임에는 분명합니다.혹시 해당 포스트를 보고 ‘어, 그거 그렇게 하는 거 아닌데…’라는 생각이 들었다면 토스페이먼츠에 와서 신나게 토론할 준비가 되어있으니 언제든 환영합니다!재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	},
	"10": {
		"createDate": "20231028",
		"title": "CommonJS와 ESM에 모두 대응하는 라이브러리 개발하기: exports field",
		"image": "https://wp.toss.tech/wp-content/uploads/2022/10/techblog-11-node-js.png",
		"content": "토스 프론트엔드 챕터에서는 개발 생산성을 극대화하기 위해 코드를 지속적으로 라이브러리로 만들고 있습니다. 그 결과 지금은 100개가 넘는 라이브러리를 운영하고 있습니다.Node.js 12부터 ECMAScript Modules라는 새로운 Module System이 추가되면서, 기존의 CommonJS라는 Module System까지, 라이브러리는 두 가지 Module System을 지원해야 하게 되었습니다.토스팀에서는 그것을 package.json의 exports field를 통해 지원하고 있습니다. 각각의 모듈 시스템과 exports field에 대해 자세히 알아봅시다.Node.js에는 CommonJS, ECMAScript Modules(이하 CJS, ESM)라는 두 가지 모듈 시스템이 존재합니다.CommonJS (CJS)// add.js\nmodule.exports.add = (x, y) => x + y;\n\n// main.js\nconst { add } = require('./add');\n\nadd(1, 2);ECMAScript Modules (ESM)// add.js\nexport function add(x, y) {\n  return x + y\n}\n\n// main.js\nimport { add } from './add.js';\n\nadd(1, 2);CJS는 require / module.exports 를 사용하고, ESM은 import / export 문을 사용합니다.CJS module loader는 동기적으로 작동하고, ESM module loader는 비동기적으로 작동합니다.ESM은 Top-level Await을 지원하기 때문에 비동기적으로 동작합니다.따라서 ESM에서 CJS를 import 할 수는 있지만, CJS에서 ESM을 require 할 수는 없습니다. 왜냐하면 CJS는 Top-level Await을 지원하지 않기 때문입니다.이 외에도 두 Module System은 기본적으로 동작이 다릅니다.따라서 두 Module System은 서로 호환되기 어렵습니다.왜 두 Module System을 지원해야해요?서로 호환되기 어려운 두 Module System을 지원해야하는 이유는 뭘까요? 그냥 하나로 통일하면 안될까요? 토스팀에서는 왜 그것을 중요하게 생각할까요?토스팀에서는 Server-side Rendering(이하 SSR)을 적극적으로 사용하고 있기 때문에, Node.js의 CJS를 지원하는 것이 중요했습니다.그리고 Module System의 지원은 브라우저 환경에서의 퍼포먼스와도 관련이 있습니다. 브라우저 환경에서는 페이지 렌더링을 빠르게 하는 것이 중요한데, 이 때 JavaScript는 로딩되어 실행되는 동안 페이지 렌더링을 중단시키는 리소스들 중 하나 입니다.따라서 JavaScript 번들의 사이즈를 줄여서 렌더링이 중단되는 시간을 최소화 하는 것이 중요합니다. 이를 위해 필요한 것이 바로 Tree-shaking입니다. Tree-shaking이란 필요하지 않은 코드와 사용되지 않는 코드를 삭제하여 JavaScript 번들의 크기를 가볍게 만드는 것을 말합니다.이 때, CJS는 Tree-shaking이 어렵고, ESM은 쉽게 가능합니다.왜냐하면 CJS는 기본적으로 require / module.exports 를 동적으로 하는 것에 아무런 제약이 없습니다.// require\nconst utilName = /* 동적인 값 */\nconst util = require(`./utils/${utilName}`);\n\n// module.exports\nfunction foo() {\n  if (/* 동적인 조건 */) {\n    module.exports = /* ... */;\n  }\n}\nfoo();따라서 CJS는 빌드 타임에 정적 분석을 적용하기가 어렵고, 런타임에서만 모듈 관계를 파악할 수 있습니다.하지만 ESM은 정적인 구조로 모듈끼리 의존하도록 강제합니다. import path에 동적인 값을 사용할 수 없고, export는 항상 최상위 스코프에서만 사용할 수 있습니다.import util from `./utils/${utilName}.js`; // 불가능\n\nimport { add } from \"./utils/math.js\"; // 가능\n\nfunction foo() {\n  export const value = \"foo\"; // 불가능\n}\n\nexport const value = \"foo\"; // 가능따라서 ESM은 빌드 단계에서 정적 분석을 통해 모듈 간의 의존 관계를 파악할 수 있고, Tree-shaking을 쉽게 할 수 있습니다.위와 같은 배경으로 토스팀에서는 CJS/ESM 모두 지원하는 라이브러리를 운영하게 되었습니다.파일이 CJS인지 ESM인지 어떻게 알아요?Module System이 두 개가 존재하며 둘 다 지원해야할 필요성은 알겠는데, .js 파일이 CJS인지 ESM인지 어떻게 알 수 있을까요? package.json의 type field 또는 확장자를 보고 알 수 있습니다..js 파일의 Module System은 package.json의 type field에 따라 결정됩니다.type field의 기본값은 \"commonjs\" 이고, 이 때 .js 는 CJS로 해석됩니다.다른 하나는 \"module\" 입니다. 이 때 .js 는 ESM으로 해석됩니다..cjs 는 항상 CJS로 해석됩니다..mjs 는 항상 ESM으로 해석됩니다.TypeScript도 4.7부터 tsconfig.json 의 moduleResolution 이 nodenext 또는 node16 으로 설정된 경우, 위 규칙이 똑같이 적용됩니다.type field가 \"commonjs\" 인 경우, .ts 는 CJS로 해석됩니다.type field가 \"module\" 인 경우, .ts 는 ESM으로 해석됩니다..cts 는 항상 CJS로 해석됩니다..mts 는 항상 ESM으로 해석됩니다.CJS와 ESM의 차이, 패키지의 기본 Module System을 설정하는 방법과 확장자 모두 알아봤는데, 그래서 어떻게 하면 하나의 패키지가 CJS/ESM을 동시에 매끄럽게 제공할 수 있을까요?정답은 exports field입니다. exports field는 무슨 문제를 해결해줄까요? 어떤 역할을 할까요?패키지 entry point 지정기본적으로는 package.json의 main field와 같은 역할을 합니다. 패키지의 entry point를 지정할 수 있습니다.subpath exports 지원기존에는 filesystem 기반으로 동작했기 때문에, 패키지 내부의 임의의 JS 파일에 접근할 수 있었고, 또한 실제 filesystem 상의 위치와 import path를 다르게 둘 수 없었습니다.// 디렉토리 구조\n/modules\n  a.js\n  b.js\n  c.js\nindex.jsrequire(\"package/a\"); // 불가능\nrequire(\"package/modules/a\"); // 가능이 때, exports field를 사용해 subpath exports를 사용하면, 명시된 subpath 외에는 사용할 수 없고, filesystem 상의 위치와 import path를 다르게 지정할 수 있습니다.// CJS 패키지\n{\n  \"name\": \"cjs-package\",\n  \"exports\": {\n    \".\": \"./index.js\",\n    \"./a\": \"./modules/a.js\",\n  },\n}// ./a.js가 아니라\n// ./modules/a.js를 불러온다.\nrequire(\"cjs-package/a\");\n\n// 에러\n// ./b는 exports field에 명시하지 않은 subpath이다.\nrequire(\"cjs-package/b\");conditional exports 지원기존에는 filesystem 기반으로 동작했기 때문에, Dual CJS/ESM 패키지를 자연스럽게 운영하기가 어려웠습니다.exports field를 사용하면, 똑같은 import path에 대해 특정 조건에 따라 다른 모듈을 제공할 수 있습니다.{\n  \"name\": \"cjs-package\",\n  \"exports\": {\n    \".\": {\n      \"require\": \"./dist/index.cjs\",\n      \"import\": \"./esm/index.mjs\"\n    }\n  }\n}// CJS 환경\n// ./dist/index.cjs를 불러온다.\nconst pkg = require(\"cjs-package\");\n\n// ESM 환경\n// ./esm/index.mjs를 불러온다.\nimport pkg from \"cjs-package\";올바른 exports fieldDual CJS/ESM 패키지의 exports field를 올바르게 작성하기 위해 주의해야할 점을 알아봅시다.상대 경로로 표시하기exports field는 모두 . 으로 시작하는 상대 경로로 작성되어야 합니다.// X\n{\n  \"exports\": {\n    \"sub-module\": \"dist/modules/sub-module.js\"\n  }\n}\n\n// O\n{\n  \"exports\": {\n    \".\": \"./dist/index.js\",\n    \"./sub-module\": \"./dist/modules/sub-module.js\"\n  }\n}Module System에 따라 올바른 확장자 사용하기conditional exports를 사용할 때, 패키지가 따르는 Module System에 따라, 즉 package.json의 type field에 따라 올바른 JS 확장자를 사용해야 합니다.CJS 패키지일 때// ESM은 .mjs로 명시해야함\n{\n  \"exports\": {\n    \".\": {\n      \"require\": \"./dist/index.js\",\n      \"import\": \"./dist/index.mjs\"\n    }\n  }\n}ESM 패키지일 때// CJS는 .cjs로 명시해야함\n{\n  \"type\": \"module\"\n  \"exports\": {\n    \".\": {\n      \"require\": \"./dist/index.cjs\",\n      \"import\": \"./dist/index.js\"\n    }\n  }\n}\n\n이 규칙을 지키지 않고 전부 .js 확장자를 사용했을 때는 어떤 일이 발생할까요? 아래와 같이 상황을 가정하겠습니다.cjs-package 는 CJS 패키지이다.type field가 \"commonjs\" 이기 때문이다../dist/index.js 는 CJS 문법(require / module.exports)으로 작성된 모듈이다../esm/index.js 는 ESM 문법(import / export)으로 작성된 모듈이다.{\n  \"name\": \"cjs-package\",\n  \"type\": \"commonjs\",\n  \"exports\": {\n    \".\": {\n      \"require\": \"./dist/index.js\",\n      \"import\": \"./esm/index.js\"\n    }\n  }\n}CJS 환경에서 cjs-package 를 require 했을 땐 잘 동작합니다. ./dist/index.js 는 CJS 모듈이고, 확장자가 .js 이므로, 가장 가까운 package.json의 type field를 따라 CJS Module Loader가 사용될 것이기 때문입니다.// 잘 동작한다.\n// ./dist/index.js를  CommonJS Module Loader로 불러온다.\nconst pkg = require(\"cjs-package\");하지만 ESM 환경에서 cjs-package 를 import 했을 땐 에러가 발생합니다. ./esm/index.js 는 ESM 모듈이지만, 확장자가 .js 이므로 가장 가까운 package.json의 type field를 따라 CJS Module Loader가 사용됩니다.ESM 문법으로 작성된 JavaScript를 CJS Module Loader로 읽기 때문에 당연히 에러가 발생합니다.(예시: import 문은 ESM에서만 사용 가능하다는 에러가 발생)// 에러가 발생한다.\n// ./esm/index.js를 CJS Module Loader로 읽었다.\nimport * as pkg from \"cjs-package\";TypeScript 지원하기TypeScript에서 module import시, 항상 Type Definition을 찾게 되는데요. 기존에는 filesystem 기반으로 Type Definition을 탐색했습니다.// ./sub-module.d.ts를 찾는다.\nimport subModule from \"package/sub-module\";\n\n하지만 TypeScript 4.7부터 moduleResolution 옵션에 node16 과 nodenext 가 정식으로 추가되었고, node16 과 nodenext 는 filesystem 기반이 아닌 exports field로부터 Type Definition을 탐색합니다. 또한, CJS TypeScript( .cts )와 ESM TypeScript( .mts )를 구분합니다.TypeScript는 conditional import의 조건 중 types 를 참조하며, 이 때 JavaScript와 마찬가지로 package.json의 type field에 따라 알맞은 확장자 ( .cts / .mts )를 사용해야 합니다.CJS 패키지// ESM TS는 mts로 명시해야함\n{\n  \"exports\": {\n    \".\": {\n      \"require\": {\n        \"types\": \"./index.d.ts\",\n        \"default\": \"./index.js\"\n      },\n      \"import\": {\n        \"types\": \"./index.d.mts\",\n        \"default\": \"./index.mjs\"\n      }\n    }\n  }\n}ESM 패키지// CJS TS는 cts로 명시해야함\n{\n  \"type\": \"module\",\n  \"exports\": {\n    \".\": {\n      \"require\": {\n        \"types\": \"./index.d.cts\",\n        \"default\": \"./index.cjs\"\n      },\n      \"import\": {\n        \"types\": \"./index.d.ts\",\n        \"default\": \"./index.js\"\n      }\n    }\n  }\n}그럼 TypeScript의 경우에는 위 규칙을 지키지 않으면 어떻게 될까요? 아래와 같이 상황을 가정하겠습니다.esm-package 는 ESM 패키지이다.type field가 \"module\" 이기 때문이다..cts (CJS TypeScript)에서 esm-package 를 사용한다.{\n  \"name\": \"esm-package\",\n  \"type\": \"module\",\n  \"exports\": {\n    \".\": {\n      \"types\": \"./index.d.ts\",\n      \"require\": \"./index.cjs\",\n      \"import\": \"./index.js\"\n    }\n  }\n}이 때 .cts (CJS TypeScript)에서 esm-package 를 require하면 타입 에러가 발생합니다.esm-package 는 Type Definition을 ./index.d.ts 만 지원합니다. 즉, ESM/CJS TypeScript 모두 ./index.d.ts 를 바라보게 됩니다.이 때, esm-package 는 ESM 패키지이기 때문에 index.d.ts 는 ESM TypeScript로써 해석됩니다.따라서 esm-package 는 CJS TypeScript 입장에서 Pure ESM Module이고, CJS는 ESM을 불러올 수 없기 때문에 esm-package 가 순수 ESM으로만 확인된다는 타입 에러가 발생합니다.// index.cts\n\n// Type Error: esm-package는 동기적으로 가져올 수 없는 ES 모듈로만 확인됩니다.\n// CJS TypeScript를 위한 .d.cts를 지원하지 않았기 때문에 발생하는 에러\nimport * as esmPkg from \"esm-package\";\n\n최근 토스팀 내부 라이브러리들은 위처럼 올바르게 exports field를 작성하여 배포되고 있습니다. CJS/ESM JavaScript는 물론 TypeScript 지원까지 잘 되있습니다.JavaScript/TypeScript 생태계는 계속해서 발전하고 있지만, TypeScript까지 잘 지원하는 라이브러리는 정말 유명한 라이브러리들 중에서도 찾아보기가 많이 힘듭니다.그렇다면 우리가 그 시작점이 되면 어떨까요? 토스팀에서는 이런 기술적인 문제를 함께 풀어가고 싶으신 분들을 언제나 환영합니다. 함께 좋은 생태계를 만들어 나가고 싶어요.Node.js의 CJS/ESM에 대해CJSESMDetermining Module Systemexports field에 대해package.json export fieldSubpath exportsConditional exportsTypeScript의 CJS/ESM 지원에 대해4.7 릴리즈 노트재미있게 읽으셨나요?좋았는지, 아쉬웠는지, 아래 이모지를 눌러 의견을 들려주세요.😍🤔아티클 공유하기"
	}
}
